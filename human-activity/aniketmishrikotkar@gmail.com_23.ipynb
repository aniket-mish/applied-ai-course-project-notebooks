{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHiAVafqKQ6J"
   },
   "source": [
    "# HumanActivityRecognition\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "This project is to build a model that predicts the human activities such as Walking, Walking_Upstairs, Walking_Downstairs, Sitting, Standing or Laying.\n",
    "\n",
    "This dataset is collected from 30 persons(referred as subjects in this dataset), performing different activities with a smartphone to their waists. The data is recorded with the help of sensors (accelerometer and Gyroscope) in that smartphone. This experiment was video recorded to label the data manually.\n",
    "\n",
    "## How data was recorded\n",
    "\n",
    "By using the sensors(Gyroscope and accelerometer) in a smartphone, they have captured '3-axial linear acceleration'(_tAcc-XYZ_) from accelerometer and '3-axial angular velocity' (_tGyro-XYZ_) from Gyroscope with several variations. \n",
    "\n",
    "> prefix 't' in those metrics denotes time.\n",
    "\n",
    "> suffix 'XYZ' represents 3-axial signals in X , Y, and Z directions.\n",
    "\n",
    "### Feature names\n",
    "\n",
    "1. These sensor signals are preprocessed by applying noise filters and then sampled in fixed-width windows(sliding windows) of 2.56 seconds each with 50% overlap. ie., each window has 128 readings. \n",
    "\n",
    "2. From Each window, a feature vector was obtianed by calculating variables from the time and frequency domain.\n",
    "> In our dataset, each datapoint represents a window with different readings \n",
    "3. The accelertion signal was saperated into Body and Gravity acceleration signals(___tBodyAcc-XYZ___ and ___tGravityAcc-XYZ___) using some low pass filter with corner frequecy of 0.3Hz.\n",
    "\n",
    "4. After that, the body linear acceleration and angular velocity were derived in time to obtian _jerk signals_ (___tBodyAccJerk-XYZ___ and ___tBodyGyroJerk-XYZ___). \n",
    "\n",
    "5. The magnitude of these 3-dimensional signals were calculated using the Euclidian norm. This magnitudes are represented as features with names like _tBodyAccMag_, _tGravityAccMag_, _tBodyAccJerkMag_, _tBodyGyroMag_ and _tBodyGyroJerkMag_.\n",
    "\n",
    "6. Finally, We've got frequency domain signals from some of the available signals by applying a FFT (Fast Fourier Transform). These signals obtained were labeled with ___prefix 'f'___ just like original signals with ___prefix 't'___. These signals are labeled as ___fBodyAcc-XYZ___, ___fBodyGyroMag___ etc.,.\n",
    "\n",
    "7. These are the signals that we got so far.\n",
    "\t+ tBodyAcc-XYZ\n",
    "\t+ tGravityAcc-XYZ\n",
    "\t+ tBodyAccJerk-XYZ\n",
    "\t+ tBodyGyro-XYZ\n",
    "\t+ tBodyGyroJerk-XYZ\n",
    "\t+ tBodyAccMag\n",
    "\t+ tGravityAccMag\n",
    "\t+ tBodyAccJerkMag\n",
    "\t+ tBodyGyroMag\n",
    "\t+ tBodyGyroJerkMag\n",
    "\t+ fBodyAcc-XYZ\n",
    "\t+ fBodyAccJerk-XYZ\n",
    "\t+ fBodyGyro-XYZ\n",
    "\t+ fBodyAccMag\n",
    "\t+ fBodyAccJerkMag\n",
    "\t+ fBodyGyroMag\n",
    "\t+ fBodyGyroJerkMag\n",
    "\n",
    "8. We can esitmate some set of variables from the above signals. ie., We will estimate the following properties on each and every signal that we recoreded so far.\n",
    "\n",
    "\t+ ___mean()___: Mean value\n",
    "\t+ ___std()___: Standard deviation\n",
    "\t+ ___mad()___: Median absolute deviation \n",
    "\t+ ___max()___: Largest value in array\n",
    "\t+ ___min()___: Smallest value in array\n",
    "\t+ ___sma()___: Signal magnitude area\n",
    "\t+ ___energy()___: Energy measure. Sum of the squares divided by the number of values. \n",
    "\t+ ___iqr()___: Interquartile range \n",
    "\t+ ___entropy()___: Signal entropy\n",
    "\t+ ___arCoeff()___: Autorregresion coefficients with Burg order equal to 4\n",
    "\t+ ___correlation()___: correlation coefficient between two signals\n",
    "\t+ ___maxInds()___: index of the frequency component with largest magnitude\n",
    "\t+ ___meanFreq()___: Weighted average of the frequency components to obtain a mean frequency\n",
    "\t+ ___skewness()___: skewness of the frequency domain signal \n",
    "\t+ ___kurtosis()___: kurtosis of the frequency domain signal \n",
    "\t+ ___bandsEnergy()___: Energy of a frequency interval within the 64 bins of the FFT of each window.\n",
    "\t+ ___angle()___: Angle between to vectors.\n",
    "\n",
    "9. We can obtain some other vectors by taking the average of signals in a single window sample. These are used on the angle() variable'\n",
    "`\n",
    "\t+ gravityMean\n",
    "\t+ tBodyAccMean\n",
    "\t+ tBodyAccJerkMean\n",
    "\t+ tBodyGyroMean\n",
    "\t+ tBodyGyroJerkMean\n",
    "\n",
    "\n",
    "###  Y_Labels(Encoded)\n",
    "+ In the dataset, Y_labels are represented as numbers from 1 to 6 as their identifiers.\n",
    "\n",
    "\t- WALKING as __1__\n",
    "\t- WALKING_UPSTAIRS as __2__\n",
    "\t- WALKING_DOWNSTAIRS as __3__\n",
    "\t- SITTING as __4__\n",
    "\t- STANDING as __5__\n",
    "\t- LAYING as __6__\n",
    "    \n",
    "## Train and test data were saperated\n",
    " - The readings from ___70%___ of the volunteers were taken as ___trianing data___ and remaining ___30%___ subjects recordings were taken for ___test data___\n",
    " \n",
    "## Data\n",
    "\n",
    "* All the data is present in 'UCI_HAR_dataset/' folder in present working directory.\n",
    "     - Feature names are present in 'UCI_HAR_dataset/features.txt'\n",
    "     - ___Train Data___\n",
    "         - 'UCI_HAR_dataset/train/X_train.txt'\n",
    "         - 'UCI_HAR_dataset/train/subject_train.txt'\n",
    "         - 'UCI_HAR_dataset/train/y_train.txt'\n",
    "     - ___Test Data___\n",
    "         - 'UCI_HAR_dataset/test/X_test.txt'\n",
    "         - 'UCI_HAR_dataset/test/subject_test.txt'\n",
    "         - 'UCI_HAR_dataset/test/y_test.txt'\n",
    "         \n",
    "\n",
    "## Data Size :\n",
    "> 27 MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xaajtB_xrqiD"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LD61V1eWrqiW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YS8vLP3rGxzw"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NOHW5Yhrqim"
   },
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txXO5n2Mrqiz"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFIE3x9Zrqi3"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9r1k9bUBrqjC"
   },
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "Cbf__XQ1sX8H",
    "outputId": "9db2ef78-e41b-4e7c-bdbf-4141f7951f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6Y16asurqjN"
   },
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'drive/My Drive/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GV4veNVyrqjW"
   },
   "outputs": [],
   "source": [
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'drive/My Drive/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7sTEd7J6rqjh"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65
    },
    "colab_type": "code",
    "id": "FDrQElnSrqjp",
    "outputId": "abcdcd08-d398-4ccd-fdd9-e3e52da43fc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkKNMKLArqj0"
   },
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hpY1XLhSrqkA",
    "outputId": "692e23c9-d639-49bc-e86b-7e25da42c353"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ft3Lj8-YrqkH"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "# import BatchNormalization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LrAZ3o6rqkW"
   },
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UVRmY5XDrqke"
   },
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_f0902CVrqko"
   },
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "YpspSrzlrqku",
    "outputId": "3fcc876b-4c68-4d35-d3ed-3cf3788c46ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vMz2n0Drqk5"
   },
   "source": [
    "<h2>Defining the Architecture of LSTM - Single Layer LSTM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "7fD8N1ltrqk7",
    "outputId": "fceb6784-e561-4107-9750-42f84aec5f94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 128)               70656     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 79,302\n",
      "Trainable params: 79,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(128, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwjZrKRerqlD"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "colab_type": "code",
    "id": "W-AXF7YdrqlK",
    "outputId": "a565ddd0-873b-4ed0-dddd-a94e88a77068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 1.4205 - acc: 0.3565 - val_loss: 1.2105 - val_acc: 0.4479\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 57s 8ms/step - loss: 1.0360 - acc: 0.5301 - val_loss: 0.7840 - val_acc: 0.6284\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 57s 8ms/step - loss: 0.9341 - acc: 0.5605 - val_loss: 1.3459 - val_acc: 0.4228\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 57s 8ms/step - loss: 0.7310 - acc: 0.6390 - val_loss: 0.6863 - val_acc: 0.6162\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 57s 8ms/step - loss: 0.5851 - acc: 0.7303 - val_loss: 0.5019 - val_acc: 0.8015\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 57s 8ms/step - loss: 0.3603 - acc: 0.8609 - val_loss: 0.3263 - val_acc: 0.8846\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 57s 8ms/step - loss: 0.2237 - acc: 0.9199 - val_loss: 0.3544 - val_acc: 0.8968\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1660 - acc: 0.9368 - val_loss: 0.2844 - val_acc: 0.9023\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 57s 8ms/step - loss: 0.1528 - acc: 0.9419 - val_loss: 0.3484 - val_acc: 0.8823\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 57s 8ms/step - loss: 0.1393 - acc: 0.9436 - val_loss: 0.2345 - val_acc: 0.9131\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1632 - acc: 0.9387 - val_loss: 0.4081 - val_acc: 0.8588\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1511 - acc: 0.9419 - val_loss: 0.2984 - val_acc: 0.9141\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1362 - acc: 0.9448 - val_loss: 0.2513 - val_acc: 0.9101\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1384 - acc: 0.9475 - val_loss: 0.3503 - val_acc: 0.8884\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1337 - acc: 0.9475 - val_loss: 0.2891 - val_acc: 0.9145\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1261 - acc: 0.9441 - val_loss: 0.3544 - val_acc: 0.9046\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1275 - acc: 0.9471 - val_loss: 0.3123 - val_acc: 0.9050\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1280 - acc: 0.9476 - val_loss: 0.3010 - val_acc: 0.9101\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1445 - acc: 0.9418 - val_loss: 0.2654 - val_acc: 0.9104\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1166 - acc: 0.9509 - val_loss: 0.2450 - val_acc: 0.9182\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "aG9eEt25rqlQ",
    "outputId": "2804450b-3d7c-49f2-fde6-e1c2e11ec588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
      "True                                 ...                                      \n",
      "LAYING                 537        0  ...                   0                 0\n",
      "SITTING                  0      380  ...                   0                 0\n",
      "STANDING                 0       88  ...                   0                 0\n",
      "WALKING                  0        0  ...                  27                 0\n",
      "WALKING_DOWNSTAIRS       0        0  ...                 418                 1\n",
      "WALKING_UPSTAIRS         0        0  ...                  10               458\n",
      "\n",
      "[6 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7H44TphOLPYl",
    "outputId": "eba6890c-20cb-49d7-9277-4b0f945c8946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 3s 921us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vyDzStKtLSAi",
    "outputId": "2c14a18d-f14a-4f83-f052-c5306c44a09a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24497356653394584, 0.9182219205972175]"
      ]
     },
     "execution_count": 171,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kNI0IoZrqls"
   },
   "source": [
    "- With a simple 2 layer architecture we got 91.82% accuracy and a loss of 0.22\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTiWcpaY067F"
   },
   "source": [
    "<h2>Architecture of LSTM - Multi Layer LSTM<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "eYolhWh1O4Fs",
    "outputId": "ff030487-37d8-4368-ccd9-24206faf6c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128, 80)           28800     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 80)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 80)                51520     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 486       \n",
      "=================================================================\n",
      "Total params: 80,806\n",
      "Trainable params: 80,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(80, return_sequences = True, input_shape=(timesteps, input_dim)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(LSTM(80)) \n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vc7UY1hNPIuX"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "y9wiIp4fQRU5",
    "outputId": "f4786c02-2267-4a76-b3dd-3c2df950b868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 1.1575 - acc: 0.5249 - val_loss: 1.2458 - val_acc: 0.4978\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.8146 - acc: 0.6601 - val_loss: 0.9396 - val_acc: 0.6016\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.6309 - acc: 0.7291 - val_loss: 0.8074 - val_acc: 0.6929\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.5919 - acc: 0.7499 - val_loss: 0.6117 - val_acc: 0.7374\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.5148 - acc: 0.7897 - val_loss: 0.6260 - val_acc: 0.7560\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.4372 - acc: 0.8308 - val_loss: 0.4171 - val_acc: 0.8456\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.3181 - acc: 0.8794 - val_loss: 0.4013 - val_acc: 0.8616\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2698 - acc: 0.9123 - val_loss: 0.4369 - val_acc: 0.8507\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1774 - acc: 0.9348 - val_loss: 0.3274 - val_acc: 0.8823\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1573 - acc: 0.9412 - val_loss: 0.4135 - val_acc: 0.8819\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1471 - acc: 0.9418 - val_loss: 0.4882 - val_acc: 0.8602\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1506 - acc: 0.9440 - val_loss: 0.4449 - val_acc: 0.8829\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1581 - acc: 0.9389 - val_loss: 0.2993 - val_acc: 0.9002\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1378 - acc: 0.9474 - val_loss: 0.3460 - val_acc: 0.8646\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1329 - acc: 0.9474 - val_loss: 0.4515 - val_acc: 0.8850\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1290 - acc: 0.9491 - val_loss: 0.3204 - val_acc: 0.9009\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1450 - acc: 0.9449 - val_loss: 0.3745 - val_acc: 0.8968\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1323 - acc: 0.9495 - val_loss: 0.2720 - val_acc: 0.9111\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1290 - acc: 0.9484 - val_loss: 0.2901 - val_acc: 0.9016\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1215 - acc: 0.9494 - val_loss: 0.3401 - val_acc: 0.8931\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1210 - acc: 0.9501 - val_loss: 0.3225 - val_acc: 0.8911\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1154 - acc: 0.9528 - val_loss: 0.6429 - val_acc: 0.8778\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1290 - acc: 0.9506 - val_loss: 0.3466 - val_acc: 0.9033\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1235 - acc: 0.9525 - val_loss: 0.3562 - val_acc: 0.9026\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1194 - acc: 0.9513 - val_loss: 0.3744 - val_acc: 0.8843\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1109 - acc: 0.9532 - val_loss: 0.3492 - val_acc: 0.8880\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1052 - acc: 0.9557 - val_loss: 0.4440 - val_acc: 0.8897\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1103 - acc: 0.9546 - val_loss: 0.4472 - val_acc: 0.8921\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1091 - acc: 0.9532 - val_loss: 0.3954 - val_acc: 0.8935\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1172 - acc: 0.9494 - val_loss: 0.3957 - val_acc: 0.9175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdaa96d1630>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=64,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "WiXL-7YKQSVe",
    "outputId": "737c19fb-8adf-4fae-d139-6ad6b03e9afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
      "True                                 ...                                      \n",
      "LAYING                 537        0  ...                   0                 0\n",
      "SITTING                  3      413  ...                   0                 1\n",
      "STANDING                 0       64  ...                   0                 0\n",
      "WALKING                  0        0  ...                  26                 3\n",
      "WALKING_DOWNSTAIRS       0        0  ...                 404                 3\n",
      "WALKING_UPSTAIRS         0        1  ...                   3               416\n",
      "\n",
      "[6 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jkmC6mItQaHD",
    "outputId": "b55471e5-7373-4dbc-fcff-45d89381916c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bm_4qfOHQbDA",
    "outputId": "896c847c-5c9c-4bfc-8d30-012e88786351"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3956586769653622, 0.9175432643366135]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sEauqDWud-nX"
   },
   "source": [
    "- With 2 LSTM layers with 80 units, dropout of 0.25 and a 2 Dense layers we get a 91.04 % accuracy.\n",
    "- In some epochs, the accuracy also goes upto 93%.\n",
    "- Tried different LSTM layers with different units, different number of dense layers but the accuracy remains in the range of 90-92%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6MxmTHSPF1o"
   },
   "source": [
    "<h2>Divide and Conquer based CNN</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kh6VUaVTXgXD"
   },
   "source": [
    "This is the code for the Sensors 2018 paper Divide and Conquer-based 1D CNN Human Activity Recognition Using Test Data Sharpening by Heeryon Cho and Sang Min Yoon.\n",
    "- This approach leverages a two-stage learning of multiple 1D CNN models.\n",
    "- We ﬁrst build a binary classiﬁer for recognizing abstract activities i.e static or dynamic.\n",
    "- Then build two multi-class 1D CNN models for recognizing individual activities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sng7yJw0PEdc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-bujtIsYKcR"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'\n",
    "\n",
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]\n",
    "\n",
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'drive/My Drive/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'drive/My Drive/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    y [y <= 3] = 0\n",
    "    y [y > 3] = 1\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset,axis = 0)\n",
    "    sigma = np.std(dataset,axis = 0)\n",
    "    return (dataset - mu)/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nt5hwCO5auSj"
   },
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train_, X_test_, Y_train_, Y_test_ = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rRfBt6ZBdJcv",
    "outputId": "533d424f-2d52-48d6-8140-c3daf49c5db0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 2)\n",
      "(2947, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_.shape)\n",
    "print(Y_test_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PdT-EAPjd7Lz"
   },
   "source": [
    "- Binary classifier to recognize activities as static and dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "2mMN7JiGdxRL",
    "outputId": "04c37cb8-a41d-4654-e57f-c5a4659651fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 126, 64)           1792      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 124, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                63520     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 71,554\n",
      "Trainable params: 71,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ = Sequential()\n",
    "model_.add(Conv1D(filters=64, kernel_size=3, activation='relu',input_shape=(128,9)))\n",
    "model_.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_.add(Dropout(0.5))\n",
    "model_.add(MaxPooling1D(pool_size=2))\n",
    "model_.add(Flatten())\n",
    "model_.add(Dense(32, activation='relu'))\n",
    "model_.add(Dense(2, activation='softmax'))\n",
    "model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "konp-f0LeSyP"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 788
    },
    "colab_type": "code",
    "id": "F1n01qnteWhu",
    "outputId": "678ce94b-133d-463a-b2d5-608c2f6b32bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 5s 624us/step - loss: 0.0848 - acc: 0.9653 - val_loss: 0.0164 - val_acc: 0.9952\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 4s 514us/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0116 - val_acc: 0.9973\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 4s 517us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0123 - val_acc: 0.9969\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 4s 515us/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0118 - val_acc: 0.9959\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 4s 514us/step - loss: 5.4784e-04 - acc: 0.9999 - val_loss: 0.0083 - val_acc: 0.9973\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 4s 521us/step - loss: 4.2276e-04 - acc: 0.9999 - val_loss: 0.0075 - val_acc: 0.9976\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 4s 523us/step - loss: 1.9288e-04 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9973\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 4s 519us/step - loss: 1.6657e-04 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9956\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 4s 515us/step - loss: 6.8173e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9969\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 4s 515us/step - loss: 4.1051e-05 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9963\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 4s 515us/step - loss: 9.8718e-05 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9969\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 4s 518us/step - loss: 7.1362e-05 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9963\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 4s 506us/step - loss: 3.7436e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9969\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 4s 508us/step - loss: 2.6072e-05 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9973\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 4s 512us/step - loss: 6.7109e-05 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9966\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 4s 521us/step - loss: 3.2977e-05 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9969\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 4s 516us/step - loss: 1.2393e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9973\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 4s 511us/step - loss: 2.3699e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9963\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 4s 510us/step - loss: 2.5019e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9973\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 4s 514us/step - loss: 4.3758e-05 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcda294e9e8>"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model_.fit(X_train_,\n",
    "          Y_train_,\n",
    "          batch_size=128,\n",
    "          validation_data=(X_test_, Y_test_),\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "JoBLX8ScNa8L",
    "outputId": "18afe93b-ff63-4eb9-b556-7394d3e7cad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "2947/2947 [==============================] - 0s 120us/step\n",
      "test loss, test acc: [0.007921562593161397, 0.997624703087886]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model_.evaluate(X_test_, Y_test_, batch_size=128)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyiyfzSxgTog"
   },
   "source": [
    "- Multi-class 1D CNN model for recognizing static activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9lstpfiIe4sR"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'\n",
    "\n",
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]\n",
    "\n",
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'drive/My Drive/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'drive/My Drive/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    static = y > 3\n",
    "    y  = y[static]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix(), static\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_tr = load_y('train')\n",
    "    y_test, y_te = load_y('test')\n",
    "    X_train = X_train[y_tr]\n",
    "    X_test = X_test[y_te]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s087-IvFj6MM"
   },
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train_static, X_test_static, Y_train_static, Y_test_static = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "AvOdml_qj-Q5",
    "outputId": "32c802b9-36d2-4dd6-9414-985ec78a0478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4067, 128, 9)\n",
      "(1560, 128, 9)\n",
      "(4067, 3)\n",
      "(1560, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_static.shape)\n",
    "print(X_test_static.shape)\n",
    "\n",
    "print(Y_train_static.shape)\n",
    "print(Y_test_static.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "I5x89wEGlnJZ",
    "outputId": "38debd8b-5d12-408f-9c9e-043c8cf91b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 122, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 122, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 61, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 976)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                62528     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 67,731\n",
      "Trainable params: 67,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_static = Sequential()\n",
    "model_static.add(Conv1D(filters=32, kernel_size=5, activation='relu', input_shape=(128,9)))\n",
    "model_static.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "model_static.add(Dropout(0.45))\n",
    "model_static.add(MaxPooling1D(pool_size=2))\n",
    "model_static.add(Flatten())\n",
    "model_static.add(Dense(64, activation='relu'))\n",
    "model_static.add(Dense(32, activation='relu'))\n",
    "model_static.add(Dense(3, activation='softmax'))\n",
    "model_static.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xj3iVnFTlt7-"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_static.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eAqCAc-XlyP1",
    "outputId": "04772f32-189b-4e15-dea4-93bec005dffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4067 samples, validate on 1560 samples\n",
      "Epoch 1/30\n",
      "4067/4067 [==============================] - 4s 888us/step - loss: 0.3417 - acc: 0.8522 - val_loss: 0.2840 - val_acc: 0.8750\n",
      "Epoch 2/30\n",
      "4067/4067 [==============================] - 1s 365us/step - loss: 0.1995 - acc: 0.9154 - val_loss: 0.2812 - val_acc: 0.8699\n",
      "Epoch 3/30\n",
      "4067/4067 [==============================] - 2s 375us/step - loss: 0.1981 - acc: 0.9125 - val_loss: 0.2710 - val_acc: 0.8667\n",
      "Epoch 4/30\n",
      "4067/4067 [==============================] - 2s 370us/step - loss: 0.1954 - acc: 0.9147 - val_loss: 0.2719 - val_acc: 0.8679\n",
      "Epoch 5/30\n",
      "4067/4067 [==============================] - 2s 370us/step - loss: 0.1960 - acc: 0.9174 - val_loss: 0.3353 - val_acc: 0.8346\n",
      "Epoch 6/30\n",
      "4067/4067 [==============================] - 1s 365us/step - loss: 0.1832 - acc: 0.9235 - val_loss: 0.2826 - val_acc: 0.8885\n",
      "Epoch 7/30\n",
      "4067/4067 [==============================] - 2s 369us/step - loss: 0.1754 - acc: 0.9243 - val_loss: 0.2936 - val_acc: 0.8679\n",
      "Epoch 8/30\n",
      "4067/4067 [==============================] - 1s 357us/step - loss: 0.1735 - acc: 0.9260 - val_loss: 0.2956 - val_acc: 0.8462\n",
      "Epoch 9/30\n",
      "4067/4067 [==============================] - 1s 354us/step - loss: 0.1697 - acc: 0.9243 - val_loss: 0.2982 - val_acc: 0.8628\n",
      "Epoch 10/30\n",
      "4067/4067 [==============================] - 1s 362us/step - loss: 0.1736 - acc: 0.9260 - val_loss: 0.2916 - val_acc: 0.8718\n",
      "Epoch 11/30\n",
      "4067/4067 [==============================] - 1s 357us/step - loss: 0.1571 - acc: 0.9304 - val_loss: 0.3313 - val_acc: 0.8673\n",
      "Epoch 12/30\n",
      "4067/4067 [==============================] - 1s 368us/step - loss: 0.1619 - acc: 0.9287 - val_loss: 0.3651 - val_acc: 0.8660\n",
      "Epoch 13/30\n",
      "4067/4067 [==============================] - 2s 370us/step - loss: 0.1543 - acc: 0.9309 - val_loss: 0.3220 - val_acc: 0.8821\n",
      "Epoch 14/30\n",
      "4067/4067 [==============================] - 2s 380us/step - loss: 0.1421 - acc: 0.9358 - val_loss: 0.3824 - val_acc: 0.8744\n",
      "Epoch 15/30\n",
      "4067/4067 [==============================] - 1s 359us/step - loss: 0.1312 - acc: 0.9405 - val_loss: 0.4430 - val_acc: 0.8910\n",
      "Epoch 16/30\n",
      "4067/4067 [==============================] - 1s 360us/step - loss: 0.1306 - acc: 0.9388 - val_loss: 0.3157 - val_acc: 0.9045\n",
      "Epoch 17/30\n",
      "4067/4067 [==============================] - 1s 357us/step - loss: 0.1355 - acc: 0.9447 - val_loss: 0.2717 - val_acc: 0.9071\n",
      "Epoch 18/30\n",
      "4067/4067 [==============================] - 1s 351us/step - loss: 0.1178 - acc: 0.9462 - val_loss: 0.2492 - val_acc: 0.9192\n",
      "Epoch 19/30\n",
      "4067/4067 [==============================] - 1s 344us/step - loss: 0.1056 - acc: 0.9518 - val_loss: 0.3187 - val_acc: 0.8955\n",
      "Epoch 20/30\n",
      "4067/4067 [==============================] - 1s 349us/step - loss: 0.0922 - acc: 0.9597 - val_loss: 0.2852 - val_acc: 0.9154\n",
      "Epoch 21/30\n",
      "4067/4067 [==============================] - 1s 363us/step - loss: 0.1001 - acc: 0.9518 - val_loss: 0.3028 - val_acc: 0.9064\n",
      "Epoch 22/30\n",
      "4067/4067 [==============================] - 1s 356us/step - loss: 0.0881 - acc: 0.9604 - val_loss: 0.3291 - val_acc: 0.8968\n",
      "Epoch 23/30\n",
      "4067/4067 [==============================] - 1s 365us/step - loss: 0.0935 - acc: 0.9540 - val_loss: 0.3228 - val_acc: 0.9103\n",
      "Epoch 24/30\n",
      "4067/4067 [==============================] - 1s 362us/step - loss: 0.0850 - acc: 0.9607 - val_loss: 0.2980 - val_acc: 0.9115\n",
      "Epoch 25/30\n",
      "4067/4067 [==============================] - 1s 361us/step - loss: 0.0831 - acc: 0.9609 - val_loss: 0.3307 - val_acc: 0.9122\n",
      "Epoch 26/30\n",
      "4067/4067 [==============================] - 1s 368us/step - loss: 0.0804 - acc: 0.9629 - val_loss: 0.3197 - val_acc: 0.9115\n",
      "Epoch 27/30\n",
      "4067/4067 [==============================] - 1s 367us/step - loss: 0.0930 - acc: 0.9599 - val_loss: 0.2880 - val_acc: 0.9224\n",
      "Epoch 28/30\n",
      "4067/4067 [==============================] - 2s 380us/step - loss: 0.0739 - acc: 0.9678 - val_loss: 0.3175 - val_acc: 0.9237\n",
      "Epoch 29/30\n",
      "4067/4067 [==============================] - 1s 367us/step - loss: 0.0793 - acc: 0.9656 - val_loss: 0.3832 - val_acc: 0.9000\n",
      "Epoch 30/30\n",
      "4067/4067 [==============================] - 2s 375us/step - loss: 0.0704 - acc: 0.9702 - val_loss: 0.3276 - val_acc: 0.9103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcda16cb588>"
      ]
     },
     "execution_count": 149,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model_static.fit(X_train_static,\n",
    "          Y_train_static,\n",
    "          batch_size=64,\n",
    "          validation_data=(X_test_static, Y_test_static),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "cQRxL4nil5Lj",
    "outputId": "e394bacb-7117-47a5-c633-287ce64a91e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "1560/1560 [==============================] - 0s 121us/step\n",
      "test loss, test acc: [0.3276318245113287, 0.9102564102564102]\n"
     ]
    }
   ],
   "source": [
    "print('\\n# Evaluate on test data')\n",
    "results = model_static.evaluate(X_test_static, Y_test_static, batch_size=32)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "juwn3As5vpl5"
   },
   "source": [
    "- Multi-class 1D CNN model for recognizing dynamic activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCRs_fUuvvcl"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'\n",
    "\n",
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]\n",
    "\n",
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'drive/My Drive/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'drive/My Drive/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    dynamic = y <= 3\n",
    "    y  = y[dynamic]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix(), dynamic\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_tr = load_y('train')\n",
    "    y_test, y_te = load_y('test')\n",
    "    X_train = X_train[y_tr]\n",
    "    X_test = X_test[y_te]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GdH5-4UTv6Hm"
   },
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train_dynamic, X_test_dynamic, Y_train_dynamic, Y_test_dynamic = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "waeyhrZiv85h",
    "outputId": "15adb24e-df1d-4be2-e11d-0e4ac1c07385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3285, 128, 9)\n",
      "(1387, 128, 9)\n",
      "(3285, 3)\n",
      "(1387, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_dynamic.shape)\n",
    "print(X_test_dynamic.shape)\n",
    "\n",
    "print(Y_train_dynamic.shape)\n",
    "print(Y_test_dynamic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "Gn2-2hd4weHC",
    "outputId": "0e07f6a9-f815-4d15-f7e4-08e7fedbbc2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_29 (Conv1D)           (None, 122, 64)           4096      \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 118, 32)           10272     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 118, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 23, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 736)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                47168     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 62,627\n",
      "Trainable params: 62,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dynamic = Sequential()\n",
    "model_dynamic.add(Conv1D(filters=64, kernel_size=7, activation='relu',input_shape=(128,9)))\n",
    "model_dynamic.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "model_dynamic.add(Dropout(0.6))\n",
    "model_dynamic.add(MaxPooling1D(pool_size=5))\n",
    "model_dynamic.add(Flatten())\n",
    "model_dynamic.add(Dense(64, activation='relu'))\n",
    "model_dynamic.add(Dense(16, activation='relu'))\n",
    "model_dynamic.add(Dense(3, activation='softmax'))\n",
    "model_dynamic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rrwZqVZwllD"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_dynamic.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "t-QpNvjewo5J",
    "outputId": "bd3a5cc9-1409-4906-e3a2-0d10ba934344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3285 samples, validate on 1387 samples\n",
      "Epoch 1/30\n",
      "3285/3285 [==============================] - 5s 2ms/step - loss: 0.7302 - acc: 0.6432 - val_loss: 0.5057 - val_acc: 0.8637\n",
      "Epoch 2/30\n",
      "3285/3285 [==============================] - 3s 841us/step - loss: 0.1185 - acc: 0.9629 - val_loss: 0.2699 - val_acc: 0.9193\n",
      "Epoch 3/30\n",
      "3285/3285 [==============================] - 3s 839us/step - loss: 0.0279 - acc: 0.9924 - val_loss: 0.1931 - val_acc: 0.9308\n",
      "Epoch 4/30\n",
      "3285/3285 [==============================] - 3s 856us/step - loss: 0.0172 - acc: 0.9942 - val_loss: 0.1125 - val_acc: 0.9668\n",
      "Epoch 5/30\n",
      "3285/3285 [==============================] - 3s 830us/step - loss: 0.0070 - acc: 0.9985 - val_loss: 0.1249 - val_acc: 0.9596\n",
      "Epoch 6/30\n",
      "3285/3285 [==============================] - 3s 829us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.1503 - val_acc: 0.9452\n",
      "Epoch 7/30\n",
      "3285/3285 [==============================] - 3s 855us/step - loss: 6.7462e-04 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9726\n",
      "Epoch 8/30\n",
      "3285/3285 [==============================] - 3s 869us/step - loss: 4.1259e-04 - acc: 1.0000 - val_loss: 0.0862 - val_acc: 0.9704\n",
      "Epoch 9/30\n",
      "3285/3285 [==============================] - 3s 840us/step - loss: 6.8230e-04 - acc: 1.0000 - val_loss: 0.0970 - val_acc: 0.9712\n",
      "Epoch 10/30\n",
      "3285/3285 [==============================] - 3s 822us/step - loss: 3.3853e-04 - acc: 1.0000 - val_loss: 0.0832 - val_acc: 0.9748\n",
      "Epoch 11/30\n",
      "3285/3285 [==============================] - 3s 850us/step - loss: 0.0026 - acc: 0.9988 - val_loss: 0.0836 - val_acc: 0.9683\n",
      "Epoch 12/30\n",
      "3285/3285 [==============================] - 3s 845us/step - loss: 0.0142 - acc: 0.9957 - val_loss: 0.1160 - val_acc: 0.9733\n",
      "Epoch 13/30\n",
      "3285/3285 [==============================] - 3s 839us/step - loss: 0.0370 - acc: 0.9884 - val_loss: 0.0807 - val_acc: 0.9769\n",
      "Epoch 14/30\n",
      "3285/3285 [==============================] - 3s 831us/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0661 - val_acc: 0.9834\n",
      "Epoch 15/30\n",
      "3285/3285 [==============================] - 3s 797us/step - loss: 6.2116e-04 - acc: 1.0000 - val_loss: 0.0653 - val_acc: 0.9834\n",
      "Epoch 16/30\n",
      "3285/3285 [==============================] - 3s 809us/step - loss: 2.1674e-04 - acc: 1.0000 - val_loss: 0.0675 - val_acc: 0.9776\n",
      "Epoch 17/30\n",
      "3285/3285 [==============================] - 3s 818us/step - loss: 2.7150e-04 - acc: 1.0000 - val_loss: 0.0818 - val_acc: 0.9733\n",
      "Epoch 18/30\n",
      "3285/3285 [==============================] - 3s 821us/step - loss: 1.4909e-04 - acc: 1.0000 - val_loss: 0.0737 - val_acc: 0.9740\n",
      "Epoch 19/30\n",
      "3285/3285 [==============================] - 3s 837us/step - loss: 9.8711e-05 - acc: 1.0000 - val_loss: 0.0643 - val_acc: 0.9769\n",
      "Epoch 20/30\n",
      "3285/3285 [==============================] - 3s 830us/step - loss: 7.2678e-05 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 0.9805\n",
      "Epoch 21/30\n",
      "3285/3285 [==============================] - 3s 821us/step - loss: 1.3984e-04 - acc: 1.0000 - val_loss: 0.0600 - val_acc: 0.9820\n",
      "Epoch 22/30\n",
      "3285/3285 [==============================] - 3s 828us/step - loss: 5.8320e-05 - acc: 1.0000 - val_loss: 0.0599 - val_acc: 0.9798\n",
      "Epoch 23/30\n",
      "3285/3285 [==============================] - 3s 828us/step - loss: 4.9516e-05 - acc: 1.0000 - val_loss: 0.0572 - val_acc: 0.9834\n",
      "Epoch 24/30\n",
      "3285/3285 [==============================] - 3s 826us/step - loss: 3.1530e-05 - acc: 1.0000 - val_loss: 0.0573 - val_acc: 0.9841\n",
      "Epoch 25/30\n",
      "3285/3285 [==============================] - 3s 817us/step - loss: 5.1674e-05 - acc: 1.0000 - val_loss: 0.0575 - val_acc: 0.9841\n",
      "Epoch 26/30\n",
      "3285/3285 [==============================] - 3s 818us/step - loss: 3.9991e-05 - acc: 1.0000 - val_loss: 0.0610 - val_acc: 0.9813\n",
      "Epoch 27/30\n",
      "3285/3285 [==============================] - 3s 844us/step - loss: 3.1905e-05 - acc: 1.0000 - val_loss: 0.0602 - val_acc: 0.9813\n",
      "Epoch 28/30\n",
      "3285/3285 [==============================] - 3s 829us/step - loss: 2.3503e-05 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 0.9834\n",
      "Epoch 29/30\n",
      "3285/3285 [==============================] - 3s 850us/step - loss: 2.0619e-05 - acc: 1.0000 - val_loss: 0.0588 - val_acc: 0.9834\n",
      "Epoch 30/30\n",
      "3285/3285 [==============================] - 3s 852us/step - loss: 1.3111e-05 - acc: 1.0000 - val_loss: 0.0571 - val_acc: 0.9841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcda15e4080>"
      ]
     },
     "execution_count": 157,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model_dynamic.fit(X_train_dynamic,\n",
    "          Y_train_dynamic,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test_dynamic, Y_test_dynamic),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "4nV0TKRpFcp-",
    "outputId": "6f7e5e16-1cee-4f3d-e7f7-550264a11388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "1387/1387 [==============================] - 0s 241us/step\n",
      "test loss, test acc: [0.057113338884291195, 0.9841384282624369]\n"
     ]
    }
   ],
   "source": [
    "print('\\n# Evaluate on test data')\n",
    "results = model_dynamic.evaluate(X_test_dynamic, Y_test_dynamic, batch_size=32)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJNkwkqfBUeP"
   },
   "source": [
    "- Pipeline for Final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2bWJNQiHRt5"
   },
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "  # classify if its static or dynamic activity\n",
    "  model_1 = model_.predict(X)\n",
    "  pred = np.argmax(model_1, axis = 1)\n",
    "\n",
    "  X_static = X[pred==1]\n",
    "  X_dynamic = X[pred==0]\n",
    "\n",
    "  # classify if its sitting, laying, standing\n",
    "  model_2 = model_static.predict(X_static)\n",
    "  pred_static = np.argmax(model_2, axis=1)\n",
    "\n",
    "  # add 4 because the classified labels are 0,1,2 and their original labels are 4,5,6\n",
    "  pred_static = pred_static + 4\n",
    "\n",
    "  # classify if its walking, walking_upstairs, walking_downstairs\n",
    "  model_3 = model_dynamic.predict(X_dynamic)\n",
    "  pred_dynamic = np.argmax(model_3, axis=1)\n",
    "\n",
    "  # add 1 because the classified labels are 0,1,2 and their original labels are 1,2,3\n",
    "  pred_dynamic = pred_dynamic + 1\n",
    "\n",
    "  i,j = 0,0 \n",
    "  final_predictions = []\n",
    "  for x in pred:\n",
    "      if x == 1:\n",
    "          final_predictions.append(pred_static[i])\n",
    "          i = i + 1\n",
    "      else:\n",
    "          final_predictions.append(pred_dynamic[j])\n",
    "          j = j + 1 \n",
    "  return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OT0MGs_i1sQP"
   },
   "outputs": [],
   "source": [
    "pred_tr = predict(X_train)\n",
    "pred_te = predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrc-r8RS8E0d"
   },
   "outputs": [],
   "source": [
    "# convert the one hot encoded array to a value\n",
    "y_tr = np.argmax(Y_train, axis = 1)\n",
    "y_tr = y_tr + 1\n",
    "\n",
    "y_te = np.argmax(Y_test, axis = 1)\n",
    "y_te = y_te + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MU_SzbeZ7H5I",
    "outputId": "e0cecf9d-f944-4612-d944-dcb711d08348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train data 0.9836779107725789\n",
      "Accuracy of test data 0.9433322022395657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of train data', accuracy_score(y_tr, pred_tr))\n",
    "print('Accuracy of test data', accuracy_score(y_te, pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "colab_type": "code",
    "id": "NBW3h6KmKf4B",
    "outputId": "bc0699d8-7c5b-4bcc-8aa7-bd2e86bda2e7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAIvCAYAAACIrfpYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzde7xVc/7H8dfndJxIJYnUOUW36XKU\n7qVyNxS5XyqGGpcYDIXBYAwGQ8bkzrj3M6gxxiCl3EI3XRSRoRB1Iroq0eX0+f2x1jm249yqvc86\ne+33cx7r0Vrf9d1rfdbZ25zP+Xy/a21zd0RERETiIivqAERERESSScmNiIiIxIqSGxEREYkVJTci\nIiISK0puREREJFaU3IiIiEisZEcdgIiIiFStGnX3ct/8Q8qO7z98O8Hd+6bsBBVQciMiIpJhfPMP\n1Gx9SsqO/+Pcexuk7OCVoORGREQk4xhYfGemxPfKREREJCOpciMiIpJpDDCLOoqUUeVGREREYkWV\nGxERkUwU4zk3Sm5EREQykYalRERERNKDKjciIiIZR7eCi4iIiKQNVW5EREQykebciIiIiKQHVW5E\nREQyjaE5NyIiIiLpQpUbERGRjGOacyMiIiKSLlS5ERERyUQxnnOj5EZERCQTaVhKREREJD2ociMi\nIpJx9PULIiIiImlDlRsREZFMY2jOjYiIiEi6UOVGREQkE2nOjYiIiEh6UOVGREQk4+huKREREZGk\nMrNFZjbPzOaa2aywrb6ZvWJmC8J/dw3bzczuMrOFZva+mXUu79hKbkRERDJRlqVuqbyD3b2ju3cN\nt68EXnP3VsBr4TZAP6BVuAwF7i/30rbqByEiIiLpzwiGpVK1bLtjgVHh+ijguIT2//PAdKCemTUq\n6yBKbkRERCTZGpjZrIRlaCl9HJhoZrMT9jd096/C9a+BhuF6LrA44bVLwrZSaUKxiIhIJkrtQ/yW\nJww1laWPuxeY2R7AK2b2v8Sd7u5m5ttyclVuREREpMq5e0H47zfAc0B3YFnRcFP47zdh9wKgScLL\n88K2Uim5ERERyTgW6ZwbM9vZzOoUrQOHAx8ALwCDw26DgefD9ReAM8K7pnoCaxKGr35Bw1IiIiJS\n1RoCz1kwNJYNPOXuL5vZTOBfZnYW8AVwSth/HHAksBBYD/y2vIMruREREclEEX5xprt/BuxbSvsK\n4NBS2h24oLLH17CUiIiIxIoqNyIiIpkoxl+/oORGREQk05hFOiyVavFN20RERCQjqXIjIiKSiWI8\nLBXfKxMREZGMpMqNiIhIJtKcGxEREZH0oMqNiIhIxjHNuRERERFJF0puRKTaMLOdzOxFM1tjZs9s\nx3FOM7OJyYwtKma2v5l9HHUcEkNFz7pJxRIxJTcistXM7FQzm2Vm68zsKzMbb2Z9knDokwi+UG83\ndz95Ww/i7k+6++FJiCelzMzNrGV5fdz9bXdvXVUxicSB5tyIyFYxs0uAK4HzgAnARqAvcCwweTsP\nvxfwibtv3s7jxIKZZetnISlhaM6NiAiAme0C3ABc4O7/cffv3X2Tu7/o7n8I+9Q0szvMbGm43GFm\nNcN9B5nZEjO71My+Cas+vw33XQ9cCwwIK0Jnmdl1ZvbPhPPvHVY7ssPtIWb2mZmtNbPPzey0hPbJ\nCa/rZWYzw+GumWbWK2HfJDP7i5lNCY8z0cwalHH9RfFfnhD/cWZ2pJl9YmYrzeyqhP7dzWyama0O\n+95jZjnhvrfCbu+F1zsg4fhXmNnXwGNFbeFrWoTn6BxuNzazb83soO16YyUDhROKU7VELPoIRCSd\n7AfsCDxXTp+rgZ5AR2BfoDtwTcL+PYFdgFzgLOBeM9vV3f8M3AyMcffa7v5IeYGY2c7AXUA/d68D\n9ALmltKvPvBS2Hc34O/AS2a2W0K3U4HfAnsAOcBl5Zx6T4KfQS5BMvYQ8BugC7A/8Cczaxb2LQSG\nAw0IfnaHAucDuPsBYZ99w+sdk3D8+gRVrKGJJ3b3T4ErgH+aWS3gMWCUu08qJ16RjKPkRkS2xm7A\n8gqGSk4DbnD3b9z9W+B64PSE/ZvC/ZvcfRywDtjWOSVbgH3MbCd3/8rdPyylz1HAAnd/wt03u/vT\nwP+AoxP6PObun7j7D8C/CBKzsmwCbnL3TcBogsTlTndfG55/PkFSh7vPdvfp4XkXAf8ADqzENf3Z\n3TeE8fyMuz8ELATeARoRJJMiW08TikVEAFgBNCgaFipDY+CLhO0vwrbiY5RIjtYDtbc2EHf/HhhA\nMPfnKzN7yczaVCKeophyE7a/3op4Vrh7YbhelHwsS9j/Q9HrzexXZjbWzL42s+8IKlOlDnkl+Nbd\nf6ygz0PAPsDd7r6hgr4iGUfJjYhsjWnABuC4cvosJRhSKdI0bNsW3wO1Erb3TNzp7hPc/dcEFYz/\nEfzSryieopgKtjGmrXE/QVyt3L0ucBXBVM7yeHk7zaw2cAfwCHBdOOwmsvU050ZEBNx9DcE8k3vD\nibS1zGwHM+tnZiPCbk8D15jZ7uHE3GuBf5Z1zArMBQ4ws6bhZOY/Fu0ws4Zmdmw492YDwfDWllKO\nMQ74VXj7eraZDQDaAWO3MaatUQf4DlgXVpV+V2L/MqD5Vh7zTmCWu59NMJfoge2OUiRmlNyIyFZx\n99uBSwgmCX8LLAYuBP4bdrkRmAW8D8wD3g3btuVcrwBjwmPN5ucJSVYYx1JgJcFclpLJA+6+AugP\nXEowrHY50N/dl29LTFvpMoLJymsJqkpjSuy/DhgV3k11SkUHM7NjCW67L7rOS4DORXeJiWyVGM+5\nMfdyK6AiIiISM1n19vKaB6VuLvqPz5872927puwEFdBD/ERERDKN6YszRURERNKGKjciIiKZqBrM\njUkVJTciIiIZyGKc3GhYSkRERGJFlRtJKsvZ2W3HeD9TrFOrhlGHkHKZcA9lfP9mlbj54otFLF++\nPKkfWSPelRslN5JUtmN9ava8OOowUmrKuPK+UzEetmyJf3qTlRXf/2OXeOndI7I7qtOWkhsREZFM\nY8S6fKk5NyIiIhIrqtyIiIhkHIv1nBtVbkRERCRWVLkRERHJQHGu3Ci5ERERyUBxTm40LCUiIiKx\nosqNiIhIBlLlRkRERCRNqHIjIiKSafQQPxEREZH0ocqNiIhIhjE9xE9EREQkfahyIyIikoFUuRER\nERFJE6rciIiIZKA4V26U3IiIiGSgOCc3GpYSERGRWFHlRkREJNPoIX4i0cvKMqbddzrP3nA8AAd2\nbMLUe09n1oNDeOgP/aiRFfxX+qsm9Zl0x6msHjuMYSd1jTLkpJg44WU65Lcmv01LbhtxS9ThpETb\nXzWjW+cO9OzWiT77dYs6nJTIhPdR1yjViZIbSQsXHt+Zj79cCYAZPPyHfpxx81i6Dn2cL5d9x28O\nzwdg1dofufS+17nj37OiDDcpCgsLGXbRBTz/4njmvD+fZ0Y/zUfz50cdVkqMn/g602fOYfK0mVGH\nknSZ8D7qGtOTmaVsiZqSG6n2chvUpm/35jz28vsA7FZ3JzZu2sLCglUAvP7uIo7r8ysAvl29ntmf\nfM2mwi2RxZssM2fMoEWLljRr3pycnBxOHjCQsS8+H3VYspUy4X3UNUp1o+RGqr3bfncIVz/8FlvC\nfGX5mh/IrpFF51YNATh+/1+Rt3udCCNMjaVLC8jLa1K8nZubR0FBQYQRpYZhHHPUEfTu2ZVHH34w\n6nCSLhPeR11j+in6+gVVbiTpzGykmQ1L2J5gZg8nbN9uZpeE68PM7Ecz2yVh/0FmNraU404ys67h\nejMzW2BmRyT2N7MhZrbFzDokvO4DM9s7XK9tZveb2adm9q6ZzTazc5L/Uyhfvx7N+Wb1euYsWPaz\n9jNufpER5x3M23edxtofNlK4xas6NEmSV994m6nvzOa5F8bxjwfuY/Lbb0UdkoikOd0tFa0pwCnA\nHWaWBTQA6ibs7wUMD9cHATOBE4DHKnNwM8sDXgYudfcJZnZQiS5LgKuBAaW8/GHgM6CVu28xs92B\nMytz3mTaLz+X/j1b0LdbM2rmZFO3Vg6PXnEkZ946jsMuHQ3AoV32olVu/aoOLeUaN85lyZLFxdsF\nBUvIzc2NMKLUaBxe0x577MExxx7HrJkz6LP/ARFHlTyZ8D7qGtNTdaiwpIoqN9GaCuwXrucDHwBr\nzWxXM6sJtAXeNbMWQG3gGoIkpzIaAROBq939hTL6jAXyzax1YmN4vu7ANe6+BcDdv3X3Wyt/aclx\n7aNv0/K0f9DmjIc44+axTJr7JWfeOo7d69UCIGeHGlx6SnceemluVYeWcl27dWPhwgUs+vxzNm7c\nyDNjRnNU/2OiDiupvv/+e9auXVu8/tqrr9Auf5+Io0quTHgfdY1pylK4REyVmwi5+1Iz22xmTQmq\nNNOAXIKEZw0wz903mtlAYDTwNtDazBq6+7IyDxwYRZCc/LucPluAEcBVwOCE9nzgvaLEpiJmNhQY\nCsCO9Srzku02/ORu9OvRnCwzHho7lzfnBn9RNdy1FlPuOZ06tXLY4s6Fx3eh0zmPsXb9xiqJK5my\ns7MZeec9HH3UERQWFjJ4yJm0y8+POqyk+mbZMgaecgIAhZs3c8rAQRx+RN+Io0quTHgfdY1S3Zi7\n5ipEycyeBF4E+gF/J0huehEkN7u5+5Vm9gFwvLsvMLO/A5+5+z3hMNNl7t6/xDEnAd8AecBh7r4+\nbC/ub2ZDgK7AMOBDoG8YR3+gA/Bbdz8+fN3VwMnAHu7euLzryarbxGv2vHj7fijV3Kpxl0UdQspt\nyYA5TFlZ1eDPS5FK6N2jK7Nnz0rqB3aH3Vt4/WNT96yebx45Zba7R/awMQ1LRW8KQTLTnmBYajpB\n5aYXMNXM2gOtgFfMbBEwkMoNTY0gmKPzjJmVWaFz983A7cAVCc3zgX3DeUC4+03u3pGfzwcSERGp\nlpTcRG8qQbVkpbsXuvtKoB5BgjOVIJG5zt33DpfGQGMz26sSxx4GfAc8YuXPHHscOAzYHcDdFwKz\ngBvNrAaAme1ItRhJFRGRZNCt4JJK8wjukppeom2Nuy8nqNQ8V+I1z4XtAIea2ZKEpWiCMh6MOQ4m\nmFw8oqwA3H0jcBewR0Lz2cBuwEIzmwW8Aly+DdcnIiJSpTShOGLuXkiJ4R53H5Kw3ryU11ySsLlT\nKYc9KKHvRuDwhH2TwvbHCSo2Rf3uIkhwira/A86txCWIiEgaqg4VllRR5UZERERiRZUbERGRDFP0\n9QtxpcqNiIiIxIoqNyIiIpkovoUbJTciIiIZxzShWERERCRtqHIjIiKSgVS5EREREUkTqtyIiIhk\nIFVuRERERNKEKjciIiKZKL6FG1VuREREJF5UuREREclAmnMjIiIikiZUuREREckwZvH+4kwlNyIi\nIhkozsmNhqVEREQkVlS5ERERyUCq3IiIiIgkkZnVMLM5ZjY23G5mZu+Y2UIzG2NmOWF7zXB7Ybh/\n74qOreRGREQkE1kKl8q5GPgoYftWYKS7twRWAWeF7WcBq8L2kWG/cim5ERERkSplZnnAUcDD4bYB\nhwD/DruMAo4L148Ntwn3H2oVjKlpzo2IiEgGSvGcmwZmNith+0F3fzBh+w7gcqBOuL0bsNrdN4fb\nS4DccD0XWAzg7pvNbE3Yf3lZJ1dyI0nVqVVDpoy7LOowUmr300ZV3CnNFYw6PeoQUi4nK76TKUWq\ngeXu3rW0HWbWH/jG3Web2UGpOLmSGxERkUxjkd4t1Rs4xsyOBHYE6gJ3AvXMLDus3uQBBWH/AqAJ\nsMTMsoFdgBXlnUBzbkRERDKMAWapW8rj7n909zx33xsYCLzu7qcBbwAnhd0GA8+H6y+E24T7X3d3\nL+8cSm5ERESkOrgCuMTMFhLMqXkkbH8E2C1svwS4sqIDaVhKREQk41SP75Zy90nApHD9M6B7KX1+\nBE7emuOqciMiIiKxosqNiIhIBqoGhZuUUeVGREREYkWVGxERkQxUHebcpIoqNyIiIhIrqtyIiIhk\nmko8jyadqXIjIiIisaLKjYiISIYxICvG36+m5EZERCQDaVhKREREJE2ociMiIpKBdCu4iIiISJpQ\n5UZERCTT6FZwERERkfShyo2IiEiGMTTnRkRERCRtqHIjIiKScUyVG5HqaOKEl+mQ35r8Ni25bcQt\nUYez3bLMmHxLf565/BAAHvhdb+bdfQJTbj2aKbceTfu9di3u26ddQ6bcejQz/nYs4/98RFQhb5ML\nzj2LFk33pGeXDsVtf73xeto0b0KfHp3p06MzE18eF2GEyRe3z2ppdI3pxyx1S9RUuZG0VFhYyLCL\nLuCl8a+Qm5dHn57d6N//GNq2axd1aNvs/CPb8nHBGurutENx2zX/nM3z73zxs3671NqBkWf15Pib\nX2XJiu9pUHfHqg51u5x6+mDOOe8Czjt7yM/az//9MC4afmk0QaVQHD+rJekapbpR5UbS0swZM2jR\noiXNmjcnJyeHkwcMZOyLz0cd1jZrXL8WR3TKY9TrCyrse3Kf5rww40uWrPgegOXf/Zjq8JKqd58D\n2LV+/ajDqDJx+6yWRteYnswsZUvUlNxIWlq6tIC8vCbF27m5eRQUFEQY0fa5dXA3/vTkLLa4/6z9\nzwM7MW3E0fz1jG7kZAf/ubZsVJd6O+cw7tojeOuv/Rl0QPMoQk66hx64l17dOnLBuWexatWqqMNJ\nmrh9Vkuja5TqRsmNSMT6ds7j2+9+ZO7nK3/W/uen36Xz8P9y4FUvUb92DsOP3QeA7KwsOjXfjZNu\nfY3jb36Fy0/Yl5aN6kYRetKcdc55zJ2/gMnvvEvDPRtxzZWXRR2SSLylcL5NNSjcpEdyY2YjzWxY\nwvYEM3s4Yft2M7skXB9mZj+a2S4J+w8ys7GlHHeSmXUN15uZ2QIzOyKxv5kNMbMtZtYh4XUfmNne\n4XptM7vfzD41s3fNbLaZnVPOtfwiFjN73MxOSojpYzN7z8ymmFnrsL2/mc0J2+eb2blmdrWZzQ2X\nwoT1ixKOPdfMRlfyfDPNrGNCvzPNbJ6ZvR9e87FlXVdVa9w4lyVLFhdvFxQsITc3N8KItl3P1ntw\nZJcmfHD3iTx+8YEcsE8jHrqwD8tW/wDAxs1beGLSQrq2aADA0pXf8+p7BazfsJkVazcw9aNl7JMw\n2Tgd7dGwITVq1CArK4vBZ57N7Fkzow4paeL0WS2LrlGqm7RIboApQC8AM8sCGgD5Cft7AVPD9UHA\nTOCEyh7czPKAl4FL3X1CKV2WAFeX8fKHgVVAK3fvDPQFtndCwWnuvi8wCrjNzHYAHgSODts7AZPc\n/SZ37+juHYEfitbd/a7wutoCNYD9zWznSpzvPuC28LV54TX3cfcOQE/g/e28rqTp2q0bCxcuYNHn\nn7Nx40aeGTOao/ofE3VY2+S6p9+lzfn/Zp/fP8uQO9/krQ++4px7JtOw3k7Fffp3a8r8xasBeGnW\nYvZr3ZAaWcZOOTXo2qoBHxesiSr8pPj6q6+K18c+/1/atssvp3d6idNntSy6xvRT9BC/uM65SZe7\npaYCI8P1fOADoJGZ7QqsB9oC75pZC6A2cD7BL+bHKnHsRsD/AVe7+wtl9BkLHGBmrd3946LG8Hzd\ngVPdfQuAu38L3LqV11eWt4BhQB2C92pFeI4NwMflvK7IIOAJgp/PscBTFfSfBvwhXN8DWAusC8+5\nrmi9JDMbCgwFaNK0aSXC2n7Z2dmMvPMejj7qCAoLCxk85Eza5cfnFyLAI7/fnwZ1d8QM3l+0kmEP\nTQfg44I1vPpeAdNvO4Yt7ox6fQEfhYlPOjjzjFOZ/PabrFi+nLYtmvLHP/2ZyW+9ybz338PMaLrX\nXtxx9wNRh5k0mfBZ1TVKdZMWyY27LzWzzWbWlKBKMw3IBfYD1gDz3H2jmQ0ERgNvA63NrKG7L6vg\n8KOAa9z93+X02QKMAK4CBie05wPvFSU2KXA0wbWtNLMXgC/M7DWCZOvpSpx3APBroA3weypObvoC\n/w3X3wOWAZ+H5/yPu79Y2ovc/UGCyhJdunT10vqkQt9+R9K335FVdboqMXn+MibPDz6y/f8yscx+\nd774IXe++GFVhZVUj/7fLz+GZww5K4JIqk4cP6sl6RrTTzUosKRMugxLQVC96cVPyc20hO0pYZ9B\nwOjwl/6zwMmVOO6rwG/MrFYF/Z4CeppZs7I6JMyBWVrOccr65Z/Y/qSZzQV6A5cBuPvZwKHAjLDt\n0fKCDecSLXf3L4HXgE5mVtZw2ZNm9jlBteve8HyFBMnOScAnwEgzu668c4qIiFQH6ZTcFM27aU8w\nLDWdoHLTC5hqZu2BVsArZrYIGEiQ7FRkBMEcnWfMrMxKlrtvBm4Hrkhong/sG84DomgODFDerSsr\ngJKzP+sDyxO2Twvnzhzn7sUz2Nx9nruPJKjGnFjBdQ0C2oQ/i0/DmMp6zWlAc4Iq1t0J53N3n+Hu\nfyX4eVZ0ThERSRNxnnOTTsnNVKA/sNLdC919JVCPIMGZSvDL/Dp33ztcGgONzWyvShx7GPAd8IiV\n/648DhwG7A7g7guBWcCNZlYDwMx2JJirVZYFYVxtw/57AfsCc8t6gQV3ZB2U0NQR+KKM7kWTrk8B\n2hf9PAjm3JSZ7Lm7A38iqE61MbPGZta5sucUEZH0olvBq4d5BHdJTS/RtsbdlxNUFp4r8ZrnwnaA\nQ81sScKyX1Gn8Bf7YILJxSPKCsDdNwJ3EUy2LXI2sBuw0MxmAa8Al5dzjA3Ab4DHwqGnfwNnu3t5\nt7sYcHl4y/Zc4HpgSDn99wcK3D1xeOwtoJ2ZNSonth8IqlN/AHYA/mZm/wvPOQC4uJxzioiIVAvm\nXmXzPyUDdOnS1ae8MyvqMFJq99NGRR1CyhWMOj3qEFKu6InPItVd7x5dmT17VlLrITvntfZ9Lngw\nmYf8mRlXHTTb3bum7AQV0H/dIiIiEitpcSt4OgonOD9RonmDu/eIIh4REZEiwUP8oo4idZTcpIi7\nzyOYhCsiIiJVSMmNiIhIxqket2yniubciIiISKyociMiIpKBYly4UeVGRERE4kWVGxERkQwU5zk3\nSm5EREQyTTX5moRU0bCUiIiIxIoqNyIiIhkmeIhffEs3qtyIiIhIrKhyIyIikoFUuRERERFJE6rc\niIiIZKAYF25UuREREZF4UeVGREQkA8V5zo2SGxERkUyjh/iJiIiIpA9VbkRERDKMYbEellLlRkRE\nRGJFlRuRrfTtk4OjDiHlWvz+uahDSLlP7z4+6hBEIhXjwo0qNyIiIhIvqtyIiIhkoKwYl25UuRER\nEZFYUeVGREQkA8W4cKPKjYiIiMSLKjciIiIZxkxfvyAiIiIxkxXf3EbDUiIiIhIvqtyIiIhkoDgP\nS6lyIyIiIrGiyo2IiEgGinHhRpUbERERiRdVbkRERDKMAUZ8Szeq3IiIiEisqHIjIiKSgfScGxER\nEZE0ocqNiIhIpjGL9XNulNyIiIhkoBjnNhqWEhERkXhR5UZERCTDGJAV49KNKjciIiISK0puJC0t\nXryYIw47mE4d2tF533zuuevOqENKiYkTXqZDfmvy27TkthG3RB3OdssymHDVwYw6fz8AhhzYnMnX\n/5qC+49n151zivvV2TGbx3/Xk1euPoTX/3Qop+zXNKqQkyJu72NpdI3pxyx1S9SU3Ehays7O5pYR\ntzPn/fm8OXk6/3jgXj6aPz/qsJKqsLCQYRddwPMvjmfO+/N5ZvTTaX+NZx/SkgVfry3envnpCgbe\nOYXFK77/Wb8hBzXnk6/W8uubXuekkW9z7Ynt2aFGNfh/zG0Qx/exJF2jVDdKbiQtNWrUiE6dOwNQ\np04d2rRpy9KlBRFHlVwzZ8ygRYuWNGvenJycHE4eMJCxLz4fdVjbrFG9HTl0n4Y8PWVRcduHS9aw\nZOX6X/R1h9o7BlMCd66ZzervN7J5i1dVqEkVt/exNLrG9GTh7eCpWKKm5EbS3heLFjF37hy6de8R\ndShJtXRpAXl5TYq3c3PzKChI3wTu+pM7cONzH7JlS8V9H5v0Ga32rMO7t/TjtWsO5c/PvI+nZ24T\nu/exNLpGqW6U3EhaW7duHYNOOZHbbr+DunXrRh2OlOGwffZk+doNzPtydaX6H9RuDz5csobOV47n\n8Jtf58YB+xZXckRk+6Vyvk1lCjdmtqOZzTCz98zsQzO7PmxvZmbvmNlCMxtjZjlhe81we2G4f+/y\njp+y5MbMRprZsITtCWb2cML27WZ2Sbg+zMx+NLNdEvYfZGZjSznuJDPrGq43M7MFZnZEYn8zG2Jm\nW8ysQ8LrPij6YZhZbTO738w+NbN3zWy2mZ1TzrXsbWY/mNkcM/sofEOGlOhznJm9H+6fZ2bHhe37\nmtnchH6DwmPtEG63N7P3E65tVkLfrmY2KVyvZWZPhsf+wMwmm9leZjY3XL42s4KE7ZyEuNzM2pS4\nng8Sfs5rwtf8z8z+ltCvoZmNDT98881sXFk/oyhs2rSJQaecyIBBp3Hc8SdEHU7SNW6cy5Ili4u3\nCwqWkJubG2FE265ri/oc3qER0288nPvO6kbv1g24a0iXMvsP2G8vxs1dCsCib79n8Yr1tGxYp6rC\nTao4vY9l0TWmpyyzlC2VsAE4xN33BToCfc2sJ3ArMNLdWwKrgLPC/mcBq8L2kWG/sq9tG38mlTEF\n6AVgZllAAyA/YX8vYGq4PgiYCVT6N5SZ5QEvA5e6+4RSuiwBri7j5Q8T/NBauXtnoC9Qv4JTfuru\nndy9LTAQGGZmvw1j2Rf4G3BsuP8Y4G9hcjUPaGpmRf/P3Av4COiUsD014Tx7mFm/Us5/MbDM3du7\n+z4Eb/TX7t7R3TsCDxB8IDqGy8bwdYOAyeG/ZXk7PEYnoL+Z9Q7bbwBecfd93b0dcGUFP6Mq4+6c\nd85ZtG7TlouHXxJ1OCnRtVs3Fi5cwKLPP2fjxo08M2Y0R/U/Juqwtsktz8+n61Uv0/OaiZz/yEym\nfLycix6fXWb/glXr6dN6dwAa1KlJ84a1+WL592X2r87i9D6WRdcoW8sD68LNHcLFgUOAf4fto4Dj\nwvVjw23C/YdaOZN7UpncTAX2C9fzgQ+AtWa2q5nVBNoC75pZC6A2cA3l/wJO1AiYCFzt7i+U0Wcs\nkG9mrRMbw/N1B65x9y0A7qD6Q8YAACAASURBVP6tu5ebBSZy98+AS4CLwqbLgJvd/fNw/+fAX4E/\nhOeYBRRNCOkC3EuY+IX/Tkk4/G2UnpQ1AooHeN39Y3ffUF6cZlYb6EOQCA2sxHX9AMwFiv4caUSQ\nJBbtf7+M8ww1s1lmNuvb5d9WdJqkmDplCk89+QRvvvE6Pbp0pEeXjrw8vloVlrZbdnY2I++8h6OP\nOoKO7dty4smn0C4/v+IXppEzD27OrJv70qjeTrx6zSHc9psg579j3Md0bV6fV685hDHD+nDzcx+y\n6vuNFRytesqE91HXmJ4shUulzm9WIxzZ+AZ4BfgUWO3um8MuS/jp91EusBgg3L8G2K2sY6dsENvd\nl5rZZjNrSvALfFoY3H5hUPPcfaOZDQRGA28Drc2sobsvq+DwowiSk3+X02cLMAK4Chic0J4PvFeU\n2GyHd4GioZ58gspNolnABeH6FKCXmU0L45pEkPzcQfCzuSHhddOA483sYGBtQvujwEQzOwl4DRjl\n7gsqiPFY4GV3/8TMVphZF3cv889lM9sVaAW8FTbdC4wxswuBV4HH3H1pyde5+4PAgwBdunStkmmf\nvfv04YdNaTrDdCv07XckffsdGXUYSTVtwXKmLVgOwKNvfMajb3z2iz7L1vzIqXdP/UV7uorj+1iS\nrlFKaJA4zQJ4MPxdUczdC4GOZlYPeI6ffqdut1RPKJ5K8Mu7KLmZlrBdVK0YBIwOk41ngZMrcdxX\ngd+YWa0K+j0F9DSzZmV1MLOrw/kmv/ilXYGtudet6OfQHZjp7p8CLc1sd6B2uJ3oRoJKVjF3nws0\nJ6js1AdmmlnbCs47iCBxJPy3rMrY/mb2HkFlaIK7fx2ec0J4zocIPnRzwphFRCTNWWpvBV/u7l0T\nlgfLisPdVwNvEBQ/6plZUeElj59GLAqAJmHc2cAuwIqyjpnq5KZo3k17gmGp6QTB9wKmmll7gkrB\nK2a2iGDopDJDUyMI5ug8k/BD+IWwdHU7cEVC83xg33AeEO5+UzjfZGtvtelEMHem6JglZ0d2AT4M\n16cD3YDeBAkeBOW2gQnbiXG/DuwE9CzRvs7d/+Pu5wP/BMr8E8LM6hOMXT4c/mz/AJxSxhjl2+Gk\nrnzgLDPrmHDOle7+lLufTvAzP6Csc4qIiFSGme0eVmwws52AXxP8Tn0DOCnsNhgoepjQC/w0CnMS\n8Lp72Q+IqIrKTX9gpbsXuvtKoB5BgjOVIJG5zt33DpfGQGMz26sSxx4GfAc8Ut6kIuBx4DBgdwB3\nX0gwZHSjmdWA4JY0tqISY8FdV38D7g6b/gb80X66G2tvguGw28NzriUYK/wtPyUz08JrSJxvk+hG\n4PKEc/YOh40I74RqB3xRTpgnAU+4+17hz7YJ8Dmwf1kvCOcK3UKYDJrZIUXVsXBCdAvgy3LOKSIi\naSD44szULZXQCHgjvFt4JsHNK2MJfv9cYmYLCebUPBL2fwTYLWy/hApucCmz6mFm5VYy3P27SgQ/\nj+AuqadKtNV29+XhfJuS1YfnCCoa7xDMhl6SsK94yMrd3cwGE0wcHgG8VEacG83sLiDxy4fOJhje\nWWhmK4AfSEgkytDCzOYAOxLMhbnL3R8PzzHXzK4AXrTgFu9NwOXhUFKRKQR3UxXdSzgNuJmf3ymV\nGPc4M0ucndsCuD9M5LLC6322nHgH8ctb5Z4toz3RA8BlYYLWBbjHzDaH53zY3WeW81oREZEKhTeo\ndCql/TOCKRwl23+kctNWALCyqjpmtpjgtqzEHKxo2909vb/JTlKiS5euPuWdWRV3lGqtxe+fizqE\nlPv07uOjDkGkUnr36Mrs2bOS+p0GuzXP9343PFVxx2305OkdZ7t715SdoALlzVdpUtY+ERERkeqq\nUreCh8NHzd395vDheQ3Lu6U4XYUTnJ8o0bzB3eP1pUUiIpLxqsH3W6ZMhcmNmd1D8OTAAwjmiKwn\nmJfRLbWhVT13n0fwGGgREZFYK/9enPRWmcpNL3fvHE6mxd1XhnfriIiIiFQ7lUluNoXPhHEAM9uN\n4Cm7IiIikoaKbgWPq8o85+ZegluId7fgK8knU8G3cYqIiIhEpcLKjbv/n5nNJngQHsDJ7v5BasMS\nERGRVMr0OTcANQgeTOek/qnGIiIiItuswkTFzK4GngYaE3yJ1VNm9sdUByYiIiKpYylcolaZys0Z\nQCd3Xw9gZjcBc4C/pjIwERERkW1RmeTmqxL9ssM2ERERSUNmkJWJc27MbCTBHJuVwIdmNiHcPpzg\nGzxFREQkTcU4tym3clN0R9SH/Pwbt6enLhwRERGR7VPeF2c+UpWBiIiISNXJ6FvBzawFcBPQDtix\nqN3df5XCuERERES2SWWeWfM48BjB3V39gH8BY1IYk4iIiKSYWeqWqFUmuanl7hMA3P1Td7+GIMkR\nERERqXYqcyv4hvCLMz81s/OAAqBOasMSERGRVDEsM28FTzAc2Bm4iGDuzS7AmakMSkRERGRbVeaL\nM98JV9cCp6c2HBEREUm5ajI3JlXKe4jfcwQP7SuVu5+QkohEREREtkN5lZt7qiwKEalWPr37+KhD\nSLl9rhwfdQhV4vnh+0cdQsq1aFg76hDSUkY+58bdX6vKQERERKTqVOZ26XQV52sTERGRDFSZu6VE\nREQkRox4D0tVunJjZjVTGYiIiIhIMlSY3JhZdzObBywIt/c1s7tTHpmIiIikTJalbolaZSo3dwH9\ngRUA7v4ecHAqgxIRERHZVpWZc5Pl7l+UGJsrTFE8IiIiUgWqQ4UlVSqT3Cw2s+6Am1kN4PfAJ6kN\nS0RERGTbVCa5+R3B0FRTYBnwatgmIiIiacgs3ndLVea7pb4BBlZBLCIiIiLbrcLkxsweopTvmHL3\noSmJSERERFIu0+fcvJqwviNwPLA4NeGIiIhIVYjxqFSlhqXGJG6b2RPA5JRFJCIiIrIdtuXrF5oB\nDZMdiIiIiFQNA7JiXLqpzJybVfw05yYLWAlcmcqgRERERLZVucmNBfeJ7QsUhE1b3P0Xk4tFREQk\nvVT6yyXTULnXFiYy49y9MFyU2IiIiEi1VpnEba6ZdUp5JCIiIlJlggf5pWaJWpnDUmaW7e6bgU7A\nTDP7FPieYB6Su3vnKopRREREpNLKm3MzA+gMHFNFsYiIiEgVMLOMvVvKANz90yqKRURERKpIjHOb\ncufc7G5ml5S1VFmEImWYOOFlOuS3Jr9NS24bcUvU4STd4sWLOeKwg+nUoR2d983nnrvujDqklIjL\n+5iTncWzF+3Hi5f0Zvxlfbj48JYA9GxZn+eH9WLcZX0YMbA9NcJn3vdoUZ85fzmMF4b35oXhvbnw\n1y2jDH+bPPHwfRx3aHeOPaQbTzx878/2Pf6Pu9gnrw6rVi6PKLrki8tnNROUV7mpAdQmrOCIVCeF\nhYUMu+gCXhr/Crl5efTp2Y3+/Y+hbbt2UYeWNNnZ2dwy4nY6de7M2rVr6dWjC4ce9utYXWOc3seN\nm7dw+gMzWL+xkOwsY/SFPXnr4+XcNrADpz8wg0XL13PxEa04oWsuz8xYAsDMz1cx9NHZEUe+bRb8\nbz7PPv04T4+dxA475HDeb47nwEP70rRZC75auoSpb71Oo9wmUYeZNHH6rBaJ83dLlVe5+crdb3D3\n60tbqixCkVLMnDGDFi1a0qx5c3Jycjh5wEDGvvh81GElVaNGjejUOZi3X6dOHdq0acvSpQUVvCq9\nxO19XL+xEIDsGsYOWcYWdzZtdhYtXw/AlE+Wc0T7eDzg/bOFH9O+Y1d22qkW2dnZdO3Zh1fHvwDA\niOuu5JKr/4LFaNwjbp/VuCsvuYnPp1JiZ+nSAvLyfvqrMDc3j4KCeP3iT/TFokXMnTuHbt17RB1K\nUsXtfcwyeGF4b9657lAmL1jBe1+uoUYNY5+8ugD07bAnjertVNy/0171ePGS3jxydldaNawdVdjb\npGXrtrw7YyqrV63ghx/W8/brE/h6aQGvTxjLHns2pk279lGHmFRx+6wWff1CqpaolTcsdWiVRSGl\nMrOrgVOBQmALcC5wK3AZcC9QE6gP7MRPT5FuBHxVSvtxwCSgq7svNzMH/u7ul4bnugyo7e7Xhdu/\nAS4nGJ7cDMwELnP31am7YinNunXrGHTKidx2+x3UrVs36nCkHFscjhk5hTo7ZnP/kM602rM2w/45\nl6uPaUtOdhaTP1lO4ZbgWagfLvmOA2+axPqNhRzYZnfuH9KZw259K+IrqLwWrdpw5vnDGXrqcexU\nqxat8zuwceMGHrr7dh586r9RhycZrszKjbuvrMpA5OfMbD+gP9DZ3TsAhwGLi/a7ew937whcC4xx\n947h0rCM9kUlTrEBOMHMGpRy7r7AcKCfu+cTPBJgKtXoC1MbN85lyZLiHwcFBUvIzc2NMKLU2LRp\nE4NOOZEBg07juONPiDqcpIvr+7j2x81M/3QlB7TenTlfrGbQfe9w4l3TmPnZKhYt/x6AdRs2Fw9j\nvfm/b8muYexaa4cow95qJw4azL/Gv82oZydQd5d6tPhVWwoWL+LEw3txeM98ln1VwMl992f5N8ui\nDnW7xfGzGueH+MX5qyXSXSNgubtvAHD35e6+NInH3ww8SJDElHQ1QZWmIDx3obs/6u4fJ/H826Vr\nt24sXLiARZ9/zsaNG3lmzGiO6h+vRzK5O+edcxat27Tl4uHxvEExTu9j/Z1zqLNjUAyvmZ1F71a7\n8dk366hfOweAnBpZDD24GU9N+xKABnVyil/bockuZJmxav2mqg98O6xY/i0AXxUs5rXxL3Dsyafy\n1nufM3H6h0yc/iENG+XyzMtv02CPavN30TaL02c1E1T4reASmYnAtWb2CfAqQRXmzSSf417gfTMb\nUaI9H3i3sgcxs6HAUIAmTZsmL7pyZGdnM/LOezj6qCMoLCxk8JAzaZefXyXnripTp0zhqSefYJ99\n2tOjS0cArr/xZvr2OzLiyJInTu/j7nVrctvADmQZZGUZ4977mjc++pYr+rfm4LZ7kGXw1LTFTF8Y\nFMX7ddiTU/dryuYtzoZNW7j4n3MjvoKtN3zoaaxetZLs7B24+qa/U3eXelGHlDJx+qwCYPG+W8r0\nXZjVl5nVAPYHDiaYb3MlMISgqjIr7DOEYB7NhSVe+4t2M1vET3Nu1rl7bTO7AdgE/EA458bMVgLN\n3H2NmbUHngDqAFe5+5jyYu7SpatPeWfW9l+8SIrtc+X4qEOoEs8P3z/qEFKuRZpNxt5avXt0Zfbs\nWUlNRXJbt/fz73sumYf8mWsOazXb3bum7AQVUOWmGnP3QoJJwJPMbB4wOAWnuYOgSvNYQtuHBPNs\n3nD3eUBHM7uHYIKyiIjEgMX4pmjNuammzKy1mbVKaOoIfJHs84QTx/8FnJXQ/Ffgb2aWl9CmxEZE\nJCaCW8FTt0RNlZvqqzZwt5nVI5j8u5BgXsu/U3Cu24Hi4St3H2dmuwPjw6Gx1cAHwIQUnFtERCSp\nlNxUU+4+G+hVyq6DSvR7HHi8lNf/ot3d905Yr52wvgyoVaLvKGDU1kUtIiLpojpUWFJFw1IiIiIS\nK6rciIiIZKA4ffdXSarciIiISKyociMiIpJhiu6WiitVbkRERCRWVLkRERHJNNXkCy5TRcmNiIhI\nBsqKcXajYSkRERGJFVVuREREMowmFIuIiIikEVVuREREMlCMp9yociMiIiLxosqNiIhIxjGyiG/p\nRpUbERERiRVVbkRERDKMoTk3IiIiImlDlRsREZFMY/F+zo2SGxERkQykr18QERERSROq3IiIiGQY\nTSgWERERSSNKbkRERDJQllnKloqYWRMze8PM5pvZh2Z2cdhe38xeMbMF4b+7hu1mZneZ2UIze9/M\nOpd7bUn5CYmIiIhU3mbgUndvB/QELjCzdsCVwGvu3gp4LdwG6Ae0CpehwP3lHVxzbkQkI739p0Oj\nDqFKNB9wb9QhpNyqscOjDiEtRTnnxt2/Ar4K19ea2UdALnAscFDYbRQwCbgibP8/d3dgupnVM7NG\n4XF+QZUbERERiYyZ7Q10At4BGiYkLF8DDcP1XGBxwsuWhG2lUuVGREQkwxgpr240MLNZCdsPuvuD\nv4jDrDbwLDDM3b+zhHKSu7uZ+bacXMmNiIiIJNtyd+9aXgcz24EgsXnS3f8TNi8rGm4ys0bAN2F7\nAdAk4eV5YVupNCwlIiKSaQzMLGVLhacPOj0CfOTuf0/Y9QIwOFwfDDyf0H5GeNdUT2BNWfNtQJUb\nERGRjBTxM/x6A6cD88xsbth2FXAL8C8zOwv4Ajgl3DcOOBJYCKwHflvewZXciIiISJVy98mUnV/9\n4lbG8C6pCyp7fCU3IiIiGcbQF2eKiIiIpA1VbkRERDJQfOs2qtyIiIhIzKhyIyIikoFiPOVGlRsR\nERGJF1VuREREMk7lHraXrpTciIiIZJgq+G6pSMX52kRERCQDqXIjIiKSgeI8LKXKjYiIiMSKKjci\nIiIZKL51G1VuREREJGZUuREREck0pjk3ItXO4sWLOeKwg+nUoR2d983nnrvujDqklDj37DNp2ngP\nunTcJ+pQUmbihJfpkN+a/DYtuW3ELVGHk1SFhYX8ev/unDHguJ+1X3P5cFrm1o8oqu2XlWVMu+c0\nnr3+WAAO6tiEqfecyvR7T+O120+heaNdAPjNr9vx5ehzmX7vaUy/9zSG9E3vz3GcP6txo+RG0lJ2\ndja3jLidOe/P583J0/nHA/fy0fz5UYeVdKcPHsLzY1+OOoyUKSwsZNhFF/D8i+OZ8/58nhn9dKze\nx4fvv5tWrdv8rO29ObNZs3p1RBElx4XHdeLjxSuLt++68FB+e+vL9LzgSca88T+uPLVH8b5n3/qE\nnhc8Sc8LnuTxlz+IItykiNtnteg5N6laolYdYhDZao0aNaJT584A1KlThzZt2rJ0aUHEUSVfn/0P\noH799P0LvyIzZ8ygRYuWNGvenJycHE4eMJCxLz4fdVhJsbRgCa9NHM+pp/+2uK2wsJC//OmPXHPD\nzRFGtn1yG9Smb7dmPJaQqDhO3Vo5ANTduSZfrfg+qvBSJs6f1TjSnBtJe18sWsTcuXPo1r1HxZ2l\nWlm6tIC8vCbF27m5ecyY8U6EESXPn/94Gdfc8FfWrV1b3PbYg/dxeL+jaLhnowgj2z63nXsQVz/y\nNrXDZAbg/JGv8txfjuPHDZv5bv1GDhw+unjfsX1a0bt9LguXrObyf0xiyfJ1UYS93eL4WdWcG9lu\nZna1mX1oZu+b2VwzeyP8d6GZrQnX55pZr7B/AzPbZGbnlTjOIjN7NmH7JDN7PFwfYmbfmtkcM1tg\nZhOKjhfuf9zMTgrXJ5nZrIR9Xc1sUsJ297DPAjN718xeMrP2qfr5bKt169Yx6JQTue32O6hbt27U\n4YgA8MrLL9Fg993p0LFzcdvXXy3lxef/w5nnXhBhZNunX/dmfLN6PXMWfvOz9t+f0Inj//RfWp7+\nME+88iG3Dj0AgHHTP6PN4Efo/rt/8tqcL3josiOiCFvKYClcoqbKTRUws/2A/kBnd99gZg2AHHdf\namYHAZe5e/8SLzsZmA4MAh4osa+LmbVz99IGfMe4+4XheQ8G/mNmB7v7R6X03cPM+rn7+BLxNgT+\nBZzq7lPDtj5AC2DeVlx6Sm3atIlBp5zIgEGncdzxJ0QdjmyDxo1zWbJkcfF2QcEScnNzI4woOWa+\nM42J41/itYkT2LDhR9au/Y6De3Yip2ZNenVqB8AP69fTq1Nbps4p7T/N6mm//Mb079mcvt33puYO\n2dStlcN/bjiW1nn1mfnx1wD8+81PeP7G4wFYufbH4tc+9vIH3HTW/pHEnQxx/azGlSo3VaMRsNzd\nNwC4+3J3X1rBawYBlwK5ZpZXYt/twNUVndTd3wAeBIaW0eW2Mo5zITCqKLEJjzXZ3f9b0Tmrirtz\n3jln0bpNWy4efknU4cg26tqtGwsXLmDR55+zceNGnhkzmqP6HxN1WNvtqj/fyOz5nzFj3ifc/8gT\n9DngID76YhnvffIlM+Z9wox5n7BTrVppldgAXPvYFFqe/jBtBj/KGbeMY9J7izn5uheou3NNWubW\nA+CQzk2LJxvvWX/n4tf279mcj79cWepx00EcP6tmqVuipspN1ZgIXGtmnwCvElRX3iyrs5k1ARq5\n+wwz+xcwgCChKfIv4Hwza1mJc78LnFvGvmnA8WGFZ21Cez4wqhLHLop3KGEC1aRp08q+bLtMnTKF\np558gn32aU+PLh0BuP7Gm+nb78gqOX9VOeM3g3j7zUksX76cFnvn8adrr2fImWdFHVbSZGdnM/LO\nezj6qCMoLCxk8JAzaZefH3VYshUKtzgX3PkKT19zNFvcWb3uR879+ysAnH9sR47q2YLNhVtYtfZH\nzrl9QsTRbjt9VtOLkpsq4O7rzKwLsD9wMDDGzK5098fLeMkAggQGYDTwKD9PbgoJqi5/BMZTvopy\n6BuBa4AryjyA2TtAXWCiu19ccr+7P0hQIaJLl65ewfmSonefPvywqUpOFan/++fTUYeQcn37HRm7\npDRRr/0PpNf+B/6ifWFB+lYxAN5+fwlvv78EgBemfsoLUz/9RZ9rH5vCtY9NqerQUiZOn9XgVvBq\nUGJJEQ1LVRF3L3T3Se7+Z4JhnxPL6T4IGGJmi4AXgA5m1qpEnyeAA4AmlK8TUGbt291fB3YCeiY0\nfwh0TujTA/gTsEsF5xIREYmckpsqYGatSyQnHYEvyuj7K6C2u+e6+97uvjfwV4KEp5i7bwJGAsPL\nOe+BBMNFD1UQ4o3A5Qnb9xIkV70S2mpVcAwREUkjmnMj26s2cLeZ1QM2Awspe5LvIOC5Em3PAmOA\nG0q0P0IwpJRoQHhnUy3gc+DEMu6UKubu48zs24Ttr81sAHCrmeUC3wDLSzm/iIhItaPkpgq4+2yg\nVxn7JgGTEravL6XP+0DbcH3vhPYNQOOE7ceBx8uJY0jC+kEl9nUpsT0d+OVEARERiQHDNOdGRERE\nJD2ociMiIpKBqsPcmFRRciMiIpJhdCu4iIiISBpR5UZERCTTVJNbtlNFlRsRERGJFVVuREREMpAq\nNyIiIiJpQpUbERGRDKSH+ImIiIikCVVuREREMowBWfEt3Ci5ERERyUQalhIRERFJE6rciIiIZCDd\nCi4iIiKSJlS5ERERyUCacyMiIiKSJlS5ERERyTBxvxVclRsRERGJFVVuREREMo5pzo2IiIhIulDl\nRkREJNNYvJ9zo+RGREQkA8U4t1FyIyKZadedc6IOoUqsGjs86hBSbtduF0YdQkpt+PjLqENIO0pu\nREREMkxwK3h8azeaUCwiIiKxosqNiIhIBopv3UaVGxEREYkZVW5EREQyUYxLN6rciIiISKyociMi\nIpKB4vz1C0puREREMlCM7wTXsJSIiIjEiyo3IiIiGSjGhRtVbkRERCReVLkRERHJRDEu3ahyIyIi\nIrGiyo2IiEiGMeJ9K7gqNyIiIhIrqtyIiIhkGtNzbkRERETShio3IiIiGSjGhRslNyIiIhkpxtmN\nhqVEREQkVpTcSNqaOOFlOuS3Jr9NS24bcUvU4STd4sWLOeKwg+nUoR2d983nnrvujDqklIj7+wi6\nxnTzv5euZ+a/rmL66CuZ/OTlAFx7/lHMGPNHpo++khfvu4BGu+8CwP5dWvH1W7cxffSVTB99JX8c\n2jfK0LeCpfR/UdOwlKSlwsJChl10AS+Nf4XcvDz69OxG//7H0LZdu6hDS5rs7GxuGXE7nTp3Zu3a\ntfTq0YVDD/t1rK4xE95HXWN66jv0Tlas/r54e+So17jhvpcAOH/QgfxxaD8uumk0AFPmfMqJFz8Q\nSZxSOlVuJC3NnDGDFi1a0qx5c3Jycjh5wEDGvvh81GElVaNGjejUuTMAderUoU2btixdWhBxVMmV\nCe+jrjEe1n7/Y/F6rZ1q4u4RRpMcZqlboqbkRtLS0qUF5OU1Kd7Ozc2joCBev/gTfbFoEXPnzqFb\n9x5Rh5JUmfA+6hrTj7vz4n0XMuXJyznzhN7F7dddcDQLxv+Fgf268pf7Xypu79GhGe+MuZL/3vM7\n2jbfM4qQpQQlN2nCzNaVs2+umY1O2D7HzMYkbNc1s0/NrLmZPW5mJ4Xtk8xsVkK/rmY2KWG7e9hn\ngZm9a2YvmVn7pF+clGvdunUMOuVEbrv9DurWrRt1OCKxd+hvR9Lr1Fs57sL7OHfA/vTu3AKA/2/v\n3uM2m+v9j7/eBhmMlJAcGuOQmBxmyKFd2VEkp+xdjNpRg213cCiiTal+ihrauwP1wxbVbzv9opRs\nVCjMyPmUQuUwg5BDI4Tx3n+sdc9cbvd9u411Xeta634/H4/r0bW+67qv670aM9fn/q7v4fPH/YS1\n3v1ZTj//avbd9W0AXP+7e3jDdp9l012P5tunX8qZ/7FPndFHTV1+1C3FTcNJeiMwDnirpKXK5pOA\nVSVtXR5/ETjZ9h+HeIsVJL17iPddETgT+Hfba9meAhwFrFH5RSyE171uZWbPvmf+8Zw5s1l55ZVr\nTNQdzzzzDNPe/0/sOu0D7PzeXeqOU7mx8OeYa2yeex98DIAHH3mcc395I5usN/F558/42VXsvNWG\nQHG76m9PPg3ABZf9lsUWHcdyyy5F1CvFTfNNA74PXAjsBODiZvC+wH9K2hjYCpgxzM/PAA4bov3j\nwKm2rxhosH2Z7R9VmH2hbbzJJtxxx+3c+ac/8fTTT3PWGafznu13rDtWpWyz797TecM6b2T/Az9Z\nd5yuGAt/jrnGZllyicVZeslXzH++9ebrcMsf7mWN1Zaf/5rtt1yf2+78MwArLjdhfvvG672eRaTn\nDUTuay3uuslsqebbFXgnsA7wCeC/AWzfKOkC4BfATrafHubnZwLvlfSPwNyO9vWAU0cTQNI+wD4A\nq6622sJcw0u26KKL8h9f/xY7vGcb5s2bxx57foR111uvJ5/dK1dcfjn//f++z+TJb2LTqcVviV84\n8sts++7tak5WnbHwj0lsoAAAHwJJREFU55hrbJYVlpvAGV/bG4BFx43jjPOv5qIrbuW0Y/Zirdev\nwHPPmbvve3j+TKn3br0Re7/vrTw7bx5PPfUMH/rMd+uM3xiSTga2Bx6wPblsezVwBjARuBN4v+1H\nJAn4OrAd8ASwp+1rR3z/Noz4HgskPW576UFtGwNft/0WSeOAu4D1bT9cnp8E/NT2uh0/c0rZ9v/L\n8TUHActQ9N4cAhxje0tJZ1P03Py4/Lkry9ddaHv/4XJOnbqxL7/y6uFOR0RU7lWbfLzuCF3199+f\nyXNPPFBpf8h660/xaef9qsq3fJ4NVptwje2Nhzsv6W3A48D3OoqbrwIP2z5a0qHAq2wfImk7il/e\ntwM2pfjeG3F2RW5LNds0YB1JdwJ/oCg+/qnj/HPlY0S2fwmMBzbraL4FmNLxmk2BzwKvfNmpIyKi\ndnVOBbf9K+DhQc07seCOwanAzh3t33NhFrCspJVGev8UNw0laRHg/cCbbE+0PZHiP4BpC/mWRwKf\n7jg+DthT0hYdbUsu5HtHRES8mBVt31c+vx9YsXy+MnBPx+tml23Dypib5lhS0uyO4xOBObbv7Wj7\nFbCupJU6/gMZFds/k/Rgx/H9knYFviJpZeAB4CGKmVcREdFwXR73+5rOpUaAE2yfMNoftm1JCz1u\nJsVNQ9geqpftC4NeMw94bcfxncDkQa/Zs+P5loPOTR10PAt4+0JGjoiIseuhkcbcDOPPA7+cl7ed\nHijb5wCrdrxulbJtWLktFRERMdb05yp+5wJ7lM/3AH7c0f4hFTYDHnuxuxPpuYmIiIieknQasCXF\n7avZwBHA0cCZkqZTzP59f/nyn1HMlLqDYir4h1/s/VPcREREjEGqcbU928NNftlqiNca+NhLef/c\nloqIiIhWSc9NRETEGCNGtx5NU6W4iYiIGINaXNvktlRERES0S3puIiIixqIWd92k5yYiIiJaJT03\nERERY1CdU8G7LT03ERER0SrpuYmIiBiD2jwVPD03ERER0SrpuYmIiBiDWtxxk56biIiIaJf03ERE\nRIxFLe66SXETERExxohMBY+IiIhojPTcREREjDXKVPCIiIiIxkjPTURExBjU4o6b9NxEREREu6Tn\nJiIiYixqcddNipuo1LXXXvPQ+MV0V48/9jXAQz3+zF7LNbZDrrEden2Nr+/hZ7VCipuolO3le/2Z\nkq62vXGvP7eXco3tkGtsh3Zco1q9zk2Km4iIiDEoU8EjIiIiGiI9N9EGJ9QdoAdyje2Qa2yHxl+j\naPV4YmS77gwRERHRQ+tvONXn/vzyrr3/6suPv6bOcUnpuYmIiBiLWtx1kzE3ERER0SrpuYmIiBiD\n2jwVPD03EVErSctJeq+kqXVniYh2SHETjSFpuqSDO47nSPqrpLmS9q0zW1Uk7SDp9R3Hn5N0g6Rz\nJa1eZ7aqSPqppMnl85WAm4GPAN+XdECt4SoiaRlJa3Ucv0/Sh8rHinVmq4qk9STt2HH8H5JOLh9T\n6sxWpTZfp9S9R91S3EST7Auc3HH8gO1lgOWBafVEqtyXgAcBJG0PfJDii/9c4Ds15qrS6rZvLp9/\nGLjI9g7AphTX2gbHAG/pOD4K2AR4G/CFWhJV72ievwXBNsB5wMXA52pJ1B1j5TpbJWNuoklk+y8d\nx2cB2H5K0viaMlXNtp8on+8C/Jfta4BrJH20xlxVeqbj+VbAiQC250p6rp5IldsE+NeO47m2PwEg\n6bJ6IlVuJdtXdBz/1fYPAST96zA/00Stvc4+6GDpmhQ30STLdh7Y/jKApEUoNrJrA0laGniC4ov/\n+I5zS9QTqXL3SPoEMBuYAvwPQFmgLlZnsAot6ucvIvYvHc+XHfzihprQeWB7s47DFXqcpZvaeZ19\ncvuoW3JbKprkQklHDtH+ReDCXofpkv8ErgeuBm61fTWApI2A++oMVqHpwHrAnsCuth8t2zcDvltX\nqIo9J+m1AwcDt+EkrQy0pXfqXkmbDm6UtBlwbw15umWsXGerpOcmmuRg4CRJdwA3lG0bUBQCe9WW\nqkK2T5Z0AcVvhDd0nLqfohhoPNsPUIyfGtx+saQ/1BCpG2YAP5H0KeC6sm0KxVicGbWlqtYhwBmS\nTgGuLdumAnsAu9YVqgtafJ3t7bpJcRONYftvwDRJkyh+8wf4re22fCECYHsOMGdQ8wSK4m7v3ieq\nnqTNgZWBX9l+QNL6wKHAW4FVaw1XAds/kPQQcCQL/lu9Gfic7fPrS1Yd278pey8+xoLC+xZgM9t/\nri1YxcbKdbZNiptoDEmrlU+fpaNXY6Dd9t115KpS+SV/DPA64EfAccC3KGYSHVtjtMpImgFsT3H7\n7ZCyp2ovihlFbZkthe3/oRxP1Fbll3vrZwy18TpFu8fcpLiJJjkPMM/vSzXFVPAVgHF1hKrYicC3\ngZnAthQFwKnAB2w/VWewCr0H2Kic5fYq4B5gsu07641VHUkjfRHa9v/pWZgukXQxxd+/odj2Vr3M\n0y1j5TrbJsVNNIbtN3UeS5pIcT98a+DLNUTqhlfYPqV8/ntJ+9v+dJ2BuuCpgULN9iOSbm9TYVP6\n2xBtS1EMpl4OaHxxAxw0RNtmwKeBB3qcpZtae50t7rhJcRPNU678ehgLbtXsZ/uZkX+qMZYoZ0YN\n/Lvz985j29cO+5PNMUnSuR3Hq3ce295xiJ9pFNvzbyFKmgDsT7Fg4em05PZiuf4SAJLeDnyWYrmC\nfdsyrgjGznW2TYqbaIxyyf7DKAZofhWYbntevakqdz/wtWGODbyj54mqt9Og41Z82Q8m6dXAJ4EP\nUNxanGL7kXpTVUvSNsDhwN+BL9m+uOZIXdHW68yYm4j+cAPF+IzzgDcDb1bH307b+9WUqzK2t6w7\nQ7fZvrTuDN1WDpreBTgBeJPtx2uOVDlJV1GMd5tBMUaMzr2WWtLLOGaus230/EU0I/qXpD0ZfmAf\ntk/tXZrukLTLSOdtn92rLN0i6SaG/nMUxQDN9XscqXLlNhJ/p5jZ13mtA9e4TC3BKiTpEkYeaNuG\nXsbWXucGG031BZfM6tr7r7Ts4tfY3rhrH/Ai0nMTjdEx0LbNdhjhnIHGFzcU08BbzXbrV38fC72M\n0PLrzG2piPpJ+gkj99y0YSDqh4c7J2nFXmbpFtt3DdUu6R8odnf/WG8TVa8cbzMs2w/3Kku3jIVe\nRhg719k2KW6iSY6pO0CvSVoW+Cdgd+CNFIv7tUY5E2x34H3An2hHzxTANbxwTaYBBib1Nk5XjIVe\nRmjxdba44ybFTTTK4rYvGuqEpK8ArRioWu6OvRPFl/5GFFsv7Az8qs5cVZG0NkUPzTTgIeAMivF/\n/1hrsGptOVwPVVuM1MvYMl9o4TpMrdf6+8LRKsdJek9ng6RFyg3tNqgnUrUk/TdwG/BO4JvAROAR\n25fYbstu0r+jmNK+ve1/sP1NoG1T+s+pO0AvSHqDpGMlnVc+jimL1zb5uaRDJbWqM0Dq7qNuKW6i\nSbYBjpX0Xpjfw3EusDgjdx03ybrAI8CtwK3lOj5tm9K4C3AfcLGkEyVtRft6yNt2PS9Qbn56CfA4\nxZT3EylWZr6k3GiyLTYCVgSukfTWusPE6LSqEo12s/0nSVsDF5SDaz8IXGX7wJqjVcb2hpLWobhl\n8/NyZ+kJklZsyw7Etn8E/EjSUhS33w4AVpD0beAc2xfWGrAaK0v6xnAn27AmE8VGktNsX9LR9iNJ\nvwSOAN5dS6qK2Z4LHChpKvALSbOB52jB0gVqcQ2edW6iMToWznodxYqvF1GsVAy0czGt8h/UacD7\ngdm2t6g50ssmaVHbzw5qexXFoOJd27ARoaS7GGEX6ZasyXSb7SFvQUn6ve039DpTt0h6B/B14ALg\nOIriBhh+9l+/23DKVF906ZVde/8Vllks69xEjFLnMv03UnQVD7S1YmsCSR+3/a2B43Jfm2skHQy0\npUv8N8CUzoZyW4ITykcb/KUNBcyLmDvCuaE2Dm0kSacDqwC7276p7jyVam/HTYqbaI6RZtO06B7/\nR4BvDW500cXaitlStPqf1PlWqjtAD6w6zK03ASv3OkwX/dz2SUOdaPrt4jb/RUxxE21xJrBa3SFi\nVJaX9MnhTtr+2nDnGuT+ugP0wMEjnLu6Zym6bHBh0/a1p9oixU20RVt+CVlf0l+HaG/NnkTAOGBp\n2vNnNpTWD2YcA7fd5mvr2lP9MGW7W1LcRFu05cvkJtsb1R2iy+6z/cW6Q3TZKm2fLSXpu4y8oeT0\nXubplnLtqbcCF1KsPfVL4I5Bs8Siz6S4icYYYW8pAcv1OE4svBb/vjjfkxRbMLTZT4doWxU4kKJ3\nri1esPaUpBb8MqVWTwVPcRNNMtLeUm3Zd+qsugP0wE6SFrP9DBSr3ALbAXe1aBPC1s+Wsv3DgeeS\nJgH/DrwNOBr4r7pyVW0srD3VRlmhOBrD9qVDPYA/Am+uO19FHpS0FoAK35X0V0k3dqzz03Q/oNhW\nAklrAjMpNpL8mKSjasxVpafrDtALktaR9APgJ8BlwLq2v227Vddv+3e2j7C9DrA/xTpbV0m6ouZo\nC020e/uF9NxEI0lanmLRt2kUsxXaspfP/sAp5fNpwPrA6hSDGL9OO9a6eZXt28vnewCn2f6EpMUp\nbuV8pr5olfnYSMVoGxaclHQWMJVirakDKfYHW0blN5vth+tL1z0da099Gji87jwxtBQ30RiSJlDs\nS7Q7sDZwNrC67VVqDVatZwdu1wDbA9+z/ReK7vCvjvBzTdI5XuEdwAwA209LasvmoMdQXOfA77CD\nx2g0fsFJYBOK6zoI+FTZ1nm9k+oI1Su2n5O0F9D2wfGNlOImmuQBitVtDwcus+2BTTRb5DlJK1EM\nYNwK+FLHufH1RKrcjZKOAeYAa1LMQhlYP6QtDgHusX0fgKQ9KNZGuRP4fH2xqmN7Yt0Z+kAf3ICJ\noWTMTTTJZ4BXAMcDn5G0Rs15uuFzFAug3Qmca/sWAElvpxhb1AZ7Aw9RjLt5l+0nyvZ1ac/A8O8A\nfweQ9DbgKIpxGo/Rni0mXkDSGpI+K+mWurP0SKNnTbV5zE02zozGKWdm7EYxJmUtih2Iz7F9W63B\nKiJpUWBCud/SQNtSFH9fH68vWYyWpBtsb1A+Pw540Pbny+PrbW9YZ74qSXodsCvF7eI3URRyZ7dl\nHyZJcxl+CYrxtht5B2SjKRv7kst/07X3X3bJcdk4M2I0JB0AXA5cZ/vLwJclTaYocn5GcYuj0cqZ\nUjOANSXdBBxke47tNm1EeDEjL/7W+F3BgXEdu59vBezTca4V/+5K2ofi797KFNufTAd+bPsLtQar\nmO0JdWeIl64Vf8lizFiFYsbQOuUX/+XAFcCxtg+rNVl1Tga+R7Gs+44UK6LuUmui6h00RNtmwKcp\nxlW1wWnApeWaKE8Cv4b5U98fqzNYhb5FMY1/d9tXA7Rjcbsxok9uH3VLiptoDNsHAZRThjcGtgA+\nDJwg6VHb69aZryITbJ9YPp8hqfFThgcrp9IC88cSfRZYAtjX9vm1BauQ7S9J+gXF7uAXesH9/0WA\nT9SXrFIrUSzHcKyk11L03ixWb6SIQoqbaKLxwDLAK8vHvUAr7u8DS0jaiAWzMMZ3HrdhfRQASdtQ\nzHr7O/Al2xfXHKlytmcN0daKcWEA5RIF3wG+I2kVinE3f5Z0K8UYuH+vNWCMSLR7qleKm2gMSScA\n6wFzgSspbkl9rXPgbQvcD3xtmGPTgvVRJF0FLE8xtmhm2TZ/wbu2FHBtJ2mzgQLO9myKxfyOlbQ2\nxYD/iNqkuIkmWY1iKvjtFGukzAYerTVRxWxvWXeGHvgb8Djwz+WjUysKuDHieOAFqzCXvVNZ2K4J\nWtx1k+ImGsP2tirWdl+PYrzNp4DJkh4GZto+otaAFZA0ePCwKdaEud723BoiVW6MFHARUaMUN9Eo\n5cDMmyU9SjHr5DGKbQreTLHeTdPtMETbq4H1JU23/cteB6qapBsoZrpdDlxh+081R4qFM0nSucOd\ntL1jL8PES6cWd92kuInGkLQfRY/NFsAzFGNurqCYPt2KAcW2PzxUu6TXU8xG2bS3ibriAxR/hu8E\njigXKJzJgmLnyjrDxag9SDHOJqLvpLiJJpkInAUcOLBnz1hh+y5JrZhma/tm4GbKbQgkvYZiAOoB\nFNsvjKsvXbwEj9u+tO4QsfCyzk1EH7D9yboz1EXSGyj3Kmo6SeOAjSh6b94CrEExQPwkytlT0QiP\nSHqt7fsBJH2IYnPQu4DP23641nTxolpc26S4iegnkn7CC7cmeDXFgmkf7H2irpgL/BY4Djg0Y24a\na1ngaZi/OejRFAsUbkjRKzd4JlxEz6S4iegvg3fFNvAX4HbbT9eQpxumA5sDewEfLte9mUkx421O\nrcnipViko3dmV+AE2z8Efijp+hpzxWi1uOsmxU1EHxntGAZJM21v3u083WD7NIq9l5C0JMVMty2A\noyQtbvv1deaLUVu07ZuDRnPlP8CIZlqi7gAvRzlDalMWjLvZBLiHYsZUNMNY2By01eqcCi5pW4qN\nkMcBJ9k+usr3T3ET0UyN3X1Z0nXAqsA1FMXMscAs24/XGixekjGyOWh0QTmp4DiK5SBmA1dJOtf2\nb6v6jBQ3EdFrewA3dXwZRkO1fXPQNhO1TgV/M3CH7T8CSDod2IliokElUtxENFNjhwLavlHSZEkH\nU2ylAXALcKztG2uMFjFmXHvtNReMX0yv6eJHLCHp6o7jE2yfUD5fmeI29IDZVLxAaYqbiGb6l7oD\nLCxJO1HMCjuKBSvcbkwxy+Yg2z+uLVzEGGF727ozdFOKm4g+Imk68GrbM8rjOcAEip6ag21/B+av\n8ttUXwTeafvOjrYbJf0S+HH5iIj2mkMx7m7AKmVbZRap8s0i4mXbl2KvrAEP2F4GWB6YVk+kyi06\nqLABoGxrxRYTETGiq4C1JK0uaXGK7VeG3YR1YaS4iegvsv2XjuOzAGw/BYyvJ1LlnpW02uDGcnPQ\nZ2vIExE9VK6N9HHgAuBW4Ezbt1T5GcqEhYj+IekO22sO0b4IxeyCSTXEqpSknYGvAl+mmA4OxZib\nQ4FDbP+ormwR0Q4pbiL6iKTjgYdtHz6o/UjgNbb3rSdZtSRtAHyKBbOlfgscY/uG+lJFRFukuIno\nI+XKvSdRrNg78EW/AXA1sFcWuouIeHEpbiL6kKRJdPRq2P5DnXmqJmkPYD9gnbLpVuAbtr9XX6qI\naItMBY/oIx0DbZ9lQc/N/Hbbd9eRq0plYXMA8EngWopp7lOAGZJs+/t15ouI5kvPTUQfkXQTxb5R\nnSsQm2Iq+Aq2x9USrEKSZgG7DZ4OLmkicLrtzWqIFREtkp6biD5i+02dx+UX/iHA1hSzi9pgmeHW\nuZG0TA15IqJlss5NRB+StJakU4DzKaZLr2v7m/WmqsyTC3kuImJUclsqoo9ImgwcRjGY+KvAabbn\n1ZuqWpKeAO4Y6hQwyfZSPY4UES2T4iaij0iaR7Fb7nnAC4oa2/v1PFTFypWIh2X7rl5liYh2ypib\niP4ynWIAcWuNtniRNNP25t3OExHtk56biOhLkq6zvVHdOSKiedJzE9FHJP2EEXpubO/Ywzh1y29e\nEbFQUtxE9Jdj6g4QEdF0KW4i+sviti8a6oSkrwCX9jhPnfTiL4mIeKGscxPRX46T9J7OBkmLlGve\nbFBPpNr8S90BIqKZUtxE9JdtgGMlvRdA0njgXGBxYIc6g1VF0nRJB3ccz5H0V0lzJe070G775noS\nRkTTZbZURJ+RtApwAfBN4IPAVbYPrDdVdSRdBWxr+y/l8XW2N5K0BHCB7bfXmzAimi5jbiL6iKQp\n5dNDgFOBi4DvD7TbvraubBXSQGFTOgvA9lNlT1VExMuSnpuIPiLp4hFO2/Y7ehamSyTdYXvNIdoX\nAe6wPamGWBHRIiluIhpC0ma2Z9Wd4+WSdDzwsO3DB7UfCbzG9r5D/2RExOikuIloCEl3216t7hwv\nl6SlgJOATYAbyuYNgKuBvWw/Xle2iGiHFDcRDSHpHtur1p2jKpImUex+DvBb23+oM09EtEeKm4iG\naFHPzYjXYPvuXmWJiHbKbKmIPjLC3lIClutxnG45j+IaO1cgNrA8sAIwro5QEdEe6bmJ6COSRlzj\nxXbrtl+QNJFi6vvWwDdsf7PWQBHReCluIhpA0qrAbrZn1J2lKpLWAg4DNgWOBU61/Uy9qSKiDbL9\nQkSfkrS8pI9K+jVwCbBizZEqIWmypNOAHwI/BybbPimFTURUJT03EX1E0gRgF2B3YG3gbGBX26vU\nGqxCkuYB91CMvZk3+Lzt/XoeKiJaJQOKI/rLA8BvgMOBy2x7YBPNFpnO0IOmIyIqkZ6biD4i6QBg\nN2Ap4DTgDOCibEkQETF6KW4i+lC5wN1uwDRgLeAI4Bzbt9UarAIjTHcHwPaOPYwTES2U4iaij5Q9\nN5cD19l+tmybTFHk7DrUhpNNMxanu0dEb2XMTUR/WQX4OrCOpJsoCp0rgGNtH1ZrsuosbvuioU5I\n+gqQ4iYiXpb03ET0IUmLAxsDWwCbl49Hba9ba7AKSLoNOND2eR1tiwAnA6+1vW1t4SKiFdJzE9Gf\nxgPLAK8sH/cCN9WaqDrbAOdLWtz2OZLGA2cBfwV2qDdaRLRBem4i+oikEyh2yp4LXAnMAmbZfqTW\nYBWTtApwAfBN4IPAVbYPrDdVRLRFViiO6C+rAa8A7gfmALOBR2tNVDFJUyg2yDwE+BLFNX5f0pTy\nXETEy5Kem4g+I0kUvTdblI/JwMPATNtH1JmtCpIuHuG0bb+jZ2EiopVS3ET0qfLWzVsoCpztgeVs\nL1tvqu6StJntWXXniIhmS3ET0Uck7ceCHptnKKaBDzxusv1cjfG6TtLdtlerO0dENFtmS0X0l4kU\nM4cOtH1fzVnqoLoDRETzpecmIvpGem4iogrpuYmInhphbykBy/U4TkS0UHpuIqKnsrdURHRbipuI\n6AuSVgV2sz2j7iwR0WxZxC8iaiNpeUkflfRr4BJgxZojRUQLZMxNRPSUpAnALsDuwNrA2cDqtlep\nNVhEtEZuS0VET0l6EvgNcDhwmW1L+qPtSTVHi4iWyG2piOi1z1Dsn3U88BlJa9ScJyJaJj03EVEL\nSZOA3YBpwFrAEcA5tm+rNVhENF6Km4joKUkHAJcD19l+tmybTFHk7Gp7zTrzRUTzpbiJiJ6SdAzF\n3lnrADdRFDpXAFfYfrjObBHRDiluIqIWkhYHNqYodDYvH4/aXrfWYBHReJkKHhF1GQ8sA7yyfNxL\n0ZMTEfGypOcmInpK0gnAesBc4EpgFjDL9iO1BouI1shU8IjotdUopoLfD8wBZgOP1pooIlolPTcR\n0XOSRNF7s0X5mAw8DMy0fUSd2SKi+VLcRERtJK0CvIWiwNkeWM72svWmioimS3ETET0laT8W9Ng8\nQzkNvHzcZPu5GuNFRAtktlRE9NpE4CzgQNv31ZwlIlooPTcRERHRKpktFREREa2S4iYiIiJaJcVN\nRPSEpHmSrpd0s6SzJC35Mt5rS0k/LZ/vKOnQEV67rKSPLsRnfF7SQaNtH/SaUyT980v4rImSbn6p\nGSNiaCluIqJXnrS9oe3JwNPAvp0nVXjJ/ybZPtf20SO8ZFngJRc3EdFcKW4iog6/BtYseyx+L+l7\nwM3AqpLeJWmmpGvLHp6lASRtK+l3kq4Fdhl4I0l7SvpW+XxFSedIuqF8bAEcDaxR9hrNKF93sKSr\nJN0o6Qsd73WYpNskXQa84cUuQtLe5fvcIOmHg3qjtpZ0dfl+25evHydpRsdn/+vL/T8yIl4oxU1E\n9JSkRYF3s2CTzLWA422vB/wNOBzY2vYU4Grgk5KWAE4EdgCmAq8d5u2/AVxqewNgCnALcCjwh7LX\n6GBJ7yo/883AhsBUSW+TNBXYrWzbDthkFJdztu1Nys+7FZjecW5i+RnvAb5TXsN04DHbm5Tvv7ek\n1UfxORHxEmSdm4jolfGSri+f/xr4L+B1wF22Z5XtmwHrApcXOzSwODATWAf4k+3bAST9ANhniM94\nB/AhANvzgMckvWrQa95VPq4rj5emKHYmAOfYfqL8jHNHcU2TJR1JcetraeCCjnNnlgsS3i7pj+U1\nvAtYv2M8zivLz75tFJ8VEaOU4iYieuVJ2xt2NpQFzN86m4CLbE8b9Lrn/dzLJOAo2/930GccsBDv\ndQqws+0bJO0JbNlxbvAiYi4/+xO2O4sgJE1ciM+OiGHktlRE9JNZwFskrQkgaSlJawO/AyZKWqN8\n3bRhfv4XwL+VPztO0iuBuRS9MgMuAD7SMZZnZUkrAL8CdpY0XtIEiltgL2YCcJ+kxYAPDDr3PkmL\nlJknAb8vP/vfytcjaW1JS43icyLiJUjPTUT0DdsPlj0gp0l6Rdl8uO3bJO0DnCfpCYrbWhOGeIv9\ngRMkTQfmAf9me6aky8up1ueX427eCMwse44eBz5o+1pJZwA3AA8AV40i8meBK4EHy//tzHQ38Btg\nGWBf209JOoliLM615c7oDwI7j+7/nYgYrWy/EBEREa2S21IRERHRKiluIiIiolVS3ERERESrpLiJ\niIiIVklxExEREa2S4iYiIiJaJcVNREREtEqKm4iIiGiV/wWqJG9yCnVufgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_te, pred_te)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "classes = ['WALKING','WALKING_UPSTAIRS','WALKING_DOWNSTAIRS','SITTING','STANDING','LAYING']\n",
    "plot_confusion_matrix(cm, classes=classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5N9Gl9-N2NR"
   },
   "source": [
    "<h2>Conclusions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "i9DvgIGHqEZT",
    "outputId": "e188f9c0-aa9d-40d1-ac6e-5500ad23bbab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+\n",
      "|        Approach        | Accuracy |\n",
      "+------------------------+----------+\n",
      "|      1 LSTM layer      |  91.82   |\n",
      "|      2 LSTM Layer      |  91.75   |\n",
      "| Divide and Conquer CNN |  94.33   |\n",
      "+------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Approach\", \"Accuracy\"]\n",
    "\n",
    "x.add_row([\"1 LSTM layer\", 91.82])\n",
    "x.add_row([\"2 LSTM Layer\", 91.75])\n",
    "x.add_row([\"Divide and Conquer CNN\", 94.33])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pIzw8UKhO9Rv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HAR_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
